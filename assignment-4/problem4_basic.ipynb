{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DAT405 Assignment 4\n",
    "\n",
    "Noah Lanai - 9808252192 - 12h work\n",
    "\n",
    "Carl Hjalmarsson - 9305198930 - 12h work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import nbdime\n",
    "import pandas as pd\n",
    "import tarfile\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem **1 a)** and **b)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract files and convert to a dataframe. Label \"ham\" and \"spam\" for readability\n",
    "def extract_files(files, m_class):  \n",
    "    rows = []\n",
    "    for fname in files:\n",
    "        tfile = tarfile.open(fname, 'r:bz2')\n",
    "        for member in tfile.getmembers():\n",
    "            f = tfile.extractfile(member)\n",
    "            if f is not None:\n",
    "                row = f.read()\n",
    "                rows.append({'message': row.decode('latin-1'), 'class': m_class})\n",
    "        tfile.close()\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# Get data for different class of email\n",
    "ham_df = extract_files(['./20021010_easy_ham.tar.bz2','./20021010_hard_ham.tar.bz2'], 'ham')\n",
    "spam_df = extract_files(['./20021010_spam.tar.bz2'], 'spam')\n",
    "\n",
    "# Get data for each type of ham\n",
    "eazy_ham_df = extract_files(['./20021010_easy_ham.tar.bz2'], 'ham')\n",
    "hard_ham_df = extract_files(['./20021010_hard_ham.tar.bz2'], 'ham')\n",
    "\n",
    "# Split up data into train and test\n",
    "hamtrain, hamtest = train_test_split(ham_df, test_size = 0.25, random_state = 0)\n",
    "spamtrain, spamtest = train_test_split(spam_df, test_size = 0.25, random_state = 0)\n",
    "\n",
    "# Merge data to one big set\n",
    "train_data = pd.concat([hamtrain, spamtrain])\n",
    "test_data = pd.concat([hamtest, spamtest])\n",
    "\n",
    "# Add spam to ham\n",
    "eazy_hamspam_df = pd.concat([eazy_ham_df, spam_df])\n",
    "hard_hamspam_df = pd.concat([hard_ham_df, spamtrain])\n",
    "\n",
    "# Replacing classes with binary numbers\n",
    "to_replace = {'ham': 0, 'spam': 1}\n",
    "train_data.replace(to_replace, inplace=True)\n",
    "test_data.replace(to_replace, inplace=True)\n",
    "eazy_hamspam_df.replace(to_replace, inplace=True)\n",
    "hard_hamspam_df.replace(to_replace, inplace=True)\n",
    "\n",
    "# Resetting index\n",
    "train_data.reset_index(drop=True, inplace=True)\n",
    "test_data.reset_index(drop=True, inplace=True)\n",
    "eazy_hamspam_df.reset_index(drop=True, inplace=True)\n",
    "hard_hamspam_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem **2 a)** and **b)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for the multinomial naive Bayes classifier:\n",
      " 0.9794437726723095\n",
      "Accuracy scorefor the Bernoulli naive Bayes classifier:\n",
      " 0.8621523579201935\n"
     ]
    }
   ],
   "source": [
    "# Fit nultinomial and Bernoulli naive Bayes classifiers\n",
    "vectorizer = CountVectorizer()\n",
    "X_train = vectorizer.fit_transform(train_data['message']).toarray()\n",
    "y_train = train_data['class']\n",
    "X_test = vectorizer.transform(test_data['message']).toarray()\n",
    "y_test = test_data['class']\n",
    "\n",
    "# Laplace smoothing, alpha=1\n",
    "mnb = MultinomialNB(alpha=1)\n",
    "mnb.fit(X_train, y_train)\n",
    "\n",
    "# binarize with value of 1\n",
    "bernb = BernoulliNB(binarize=1)\n",
    "bernb.fit(X_train, y_train)\n",
    "\n",
    "# Run multinomial and Bernoulli naive Bayes classifiers\n",
    "mnb_predict = mnb.predict(X_test)\n",
    "print(\"Accuracy score for the multinomial naive Bayes classifier:\\n\", metrics.accuracy_score(y_test, mnb_predict))\n",
    "\n",
    "bernb_predict = bernb.predict(X_test)\n",
    "print(\"Accuracy scorefor the Bernoulli naive Bayes classifier:\\n\", metrics.accuracy_score(y_test, bernb_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Differences between models**\n",
    "The multinomial naive Bayes model implements the naive Bayes algorithm for multinomially distributed data, which is a generalisation of the binomial distribution. For n number of trials it calculates the probability of **x_k** number of successes for **k** different features, i.e. the probability of finding **k** different words in the same text **x_k** number of times. The algorithm calculates the maximum likelihood of a specific word occuring given a specified class, to be used in the naive Bayes formula, based on word count vectors. If a word does not occur it is ignored in the calculation of the maximum likelihood.\n",
    "\n",
    "The Bernoulli naive Bayes model implements the naive Bayes algorithm for multivariate Bernoulli distributed data, which means that each feature has to be condensed to a binary value, which is done using the binarize parameter to provide a threshold for feature count. This gives binary-valued feature vectors, meaning that the word counts for each individual word is condensed to either 1 or 0 depending on the threshold. The algorithm calculates the likelihood of a specific word occuring, to be used in the naive Bayes formula, based on these binary-valued feature vectors. This version of calculating the maximum likelihood also penalizes non-occurrence of a word. \n",
    "\n",
    "The main differences are the distributions used to calculate the probability terms of the naive Bayes formula. Adding to this, the main difference seems to be in how it calculates the likelihood terms, and what inputs to use for this calculation; the feature vectors.\n",
    "\n",
    "#### **Choice of binarize**\n",
    "The Bernoulli model seemed to fair worse when increasing the binarize variable from the default value of 0, which is why we decided to keep the default value.\n",
    "\n",
    "#### Differences in performance\n",
    "Referring to the scikit-learn.org page, it states that the Bernoulli naive Bayes model might perform better on some datasets, especially those with shorter documents. We found this not to be the case when comparing since email messages are usually quite short in comparison to other texts. When discarding the word counts we lose information which might impact the result, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 **i. and ii.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Labels in y_true and y_pred should be of the same type. Got y_true=['ham' 'spam'] and y_pred=[0 1]. Make sure that the predictions provided by the classifier coincides with the true labels.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/dat405/lib/python3.8/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m                 \u001b[0munique_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munion1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36munion1d\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dat405/lib/python3.8/site-packages/numpy/lib/arraysetops.py\u001b[0m in \u001b[0;36munion1d\u001b[0;34m(ar1, ar2)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \"\"\"\n\u001b[0;32m--> 777\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mar1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mar2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36munique\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dat405/lib/python3.8/site-packages/numpy/lib/arraysetops.py\u001b[0m in \u001b[0;36munique\u001b[0;34m(ar, return_index, return_inverse, return_counts, axis)\u001b[0m\n\u001b[1;32m    271\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_unique1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_counts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_unpack_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dat405/lib/python3.8/site-packages/numpy/lib/arraysetops.py\u001b[0m in \u001b[0;36m_unique1d\u001b[0;34m(ar, return_index, return_inverse, return_counts)\u001b[0m\n\u001b[1;32m    332\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 333\u001b[0;31m         \u001b[0mar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    334\u001b[0m         \u001b[0maux\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: '<' not supported between instances of 'int' and 'str'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_14707/460602384.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmnb_predict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmnb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_eazy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Eazy ham vs spam: Accuracy score for the multinomial naive Bayes classifier:\\n\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_eazy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmnb_predict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mbernb_predict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbernb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_eazy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dat405/lib/python3.8/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"multilabel\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dat405/lib/python3.8/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;31m# `y_pred` given by the classifier will also be encoded with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0;31m# strings. So we raise a meaningful error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m                 raise TypeError(\n\u001b[0m\u001b[1;32m    118\u001b[0m                     \u001b[0;34m\"Labels in y_true and y_pred should be of the same type. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m                     \u001b[0;34mf\"Got y_true={np.unique(y_true)} and \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Labels in y_true and y_pred should be of the same type. Got y_true=['ham' 'spam'] and y_pred=[0 1]. Make sure that the predictions provided by the classifier coincides with the true labels."
     ]
    }
   ],
   "source": [
    "# Eazy ham vs spam classifier\n",
    "X_eazy = vectorizer.transform(eazy_hamspam_df['message']).toarray()\n",
    "y_eazy = eazy_hamspam_df['class']\n",
    "\n",
    "mnb_predict = mnb.predict(X_eazy)\n",
    "print(\"Eazy ham vs spam: Accuracy score for the multinomial naive Bayes classifier:\\n\", metrics.accuracy_score(y_eazy, mnb_predict))\n",
    "\n",
    "bernb_predict = bernb.predict(X_eazy)\n",
    "print(\"Eazy ham vs spam: Accuracy scorefor the Bernoulli naive Bayes classifier:\\n\", metrics.accuracy_score(y_eazy, bernb_predict))\n",
    "\n",
    "# Hard ham vs spam classifier\n",
    "X_hard = vectorizer.transform(hard_hamspam_df['message']).toarray()\n",
    "y_hard = hard_hamspam_df['class']\n",
    "\n",
    "mnb_predict = mnb.predict(X_hard)\n",
    "print(\"Hard ham vs spam: Accuracy score for the multinomial naive Bayes classifier:\\n\", metrics.accuracy_score(y_hard, mnb_predict))\n",
    "\n",
    "bernb_predict = bernb.predict(X_hard)\n",
    "print(\"Hard ham vs spam: Accuracy scorefor the Bernoulli naive Bayes classifier:\\n\", metrics.accuracy_score(y_hard, bernb_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Differences in performance\n",
    "Referring to the scikit-learn.org page, it states that the Bernoulli naive Bayes model might perform better on some datasets, especially those with shorter documents. We found this not to be the case since email messages are usually quite short in comparison to other texts. When discarding the word counts we lose information which might impact the result,"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8dede480c75803c6afe94270c90f6b71384aaa9607279584a745202969843126"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('data_ai': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
