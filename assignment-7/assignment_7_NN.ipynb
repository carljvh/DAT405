{"cells":[{"cell_type":"markdown","source":["### Assignment 7"],"metadata":{"id":"3ESlw2ddzMyZ"}},{"cell_type":"markdown","source":["Noah Lanai - 9808252192 - 18h\n","\n","Carl Hjalmarsson - 9305198930 - 18h"],"metadata":{"id":"ovqpDc41yJA9"}},{"cell_type":"code","source":["# imports\n","from __future__ import print_function\n","import tensorflow.keras\n","from keras.datasets import mnist\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Flatten\n","from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n","from keras import backend as K\n","import tensorflow as tf\n","import numpy as np\n","from matplotlib import pyplot as plt"],"metadata":{"id":"8raP6MrsiBEf","executionInfo":{"status":"ok","timestamp":1639734101859,"user_tz":-60,"elapsed":3247,"user":{"displayName":"Noah Lanai","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3gMuaTxwLJbby0Vp5tDORsb1KtaWfwA3UALybUw=s64","userId":"07227027853094350298"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","execution_count":2,"metadata":{"id":"BJRCoRmew8Zd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1639734106372,"user_tz":-60,"elapsed":1675,"user":{"displayName":"Noah Lanai","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3gMuaTxwLJbby0Vp5tDORsb1KtaWfwA3UALybUw=s64","userId":"07227027853094350298"}},"outputId":"880d5538-c494-43e1-c411-4d7831ed09ef"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11493376/11490434 [==============================] - 0s 0us/step\n","11501568/11490434 [==============================] - 0s 0us/step\n"]}],"source":["# Hyper-parameters data-loading and formatting\n","\n","batch_size = 128\n","num_classes = 10\n","epochs = 10\n","\n","img_rows, img_cols = 28, 28\n","\n","(x_train, lbl_train), (x_test, lbl_test) = mnist.load_data()\n","if K.image_data_format() == 'channels_first':\n","    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n","    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n","    input_shape = (1, img_rows, img_cols)\n","else:\n","    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n","    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n","    input_shape = (img_rows, img_cols, 1)"]},{"cell_type":"markdown","metadata":{"id":"-I3g1RrZ0wpI"},"source":["**Preprocessing**"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"UswCCQLS0s1I","executionInfo":{"status":"ok","timestamp":1639734109415,"user_tz":-60,"elapsed":399,"user":{"displayName":"Noah Lanai","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3gMuaTxwLJbby0Vp5tDORsb1KtaWfwA3UALybUw=s64","userId":"07227027853094350298"}}},"outputs":[],"source":["x_train = x_train.astype('float32')\n","x_test = x_test.astype('float32')\n","\n","x_train /= 255\n","x_test /= 255\n","\n","y_train = tf.keras.utils.to_categorical(lbl_train, num_classes)\n","y_test = tf.keras.utils.to_categorical(lbl_test, num_classes)\n"]},{"cell_type":"markdown","source":["### Question 1\n","The image data for the train and test sets are integers, which means that integer division applies. Dividing by 255 would then discard the fractional part of the values.\n","\n","We divide by 255 since the MNIST data set consists of images represented in grayscale as numbers between 0 and 255. In order to simplify calculations, which speeds up learning and leads to faster convergence, we normalize data so that each value $x_{ij} \\in [0,1]$.\n","\n","The ```to_categorical()``` method converts the class vectors of ```y_train``` and ```y_test``` to a binary matrix. This is done because of the output of the last layer will be one scalar value from each of the ten neurons for each image, where the scalar value is a measurement of how much a specific number they think the image contains. The propagation is done in batches, which is why the output will have the format of ```[batch_size, num_classes]```. In order to compare this output to the labels and calculate the loss when using categorical crossentropy, the labels need to have the same dimensions, i.e. one row for each image in the batch and one column for each category (read class).\n"],"metadata":{"id":"Y6sO7MDSfEx3"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"N7Aer42gk1W9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1639646343538,"user_tz":-60,"elapsed":3996,"user":{"displayName":"Carl Hjalmarsson","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjPhXRyxfUmz6QECuK-KbhNTYdiIjr8547K5LaklQ=s64","userId":"03986481713830842027"}},"outputId":"36551d42-05a3-4ea6-89e8-2e3bb9318704"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super(SGD, self).__init__(name, **kwargs)\n"]}],"source":["## Define model ##\n","model = Sequential()\n","\n","model.add(Flatten())\n","model.add(Dense(64, activation = 'relu'))\n","model.add(Dense(64, activation = 'relu'))\n","model.add(Dense(num_classes, activation='softmax'))\n","\n","model.compile(loss=tf.keras.losses.categorical_crossentropy,\n","               optimizer=tf.keras.optimizers.SGD(lr = 0.1),\n","        metrics=['accuracy'])"]},{"cell_type":"markdown","source":["### Question 2\n","### a)\n","The model has three layers with $64+64+10 = 138$ neurons. \n","\n","The ReLu activation function is used for the first two layers. This is appropriate for this application as we have many neurons firing between each layer, and the main advantage of ReLU is that it does not activate all the neurons at the same time, making it computationally efficient. It also has better gradient propagation as it is piecewise linear; since we are dealing with numbers between 0 and 1, the gradient can become very small also known as *vanishing gradient* issues, causing the weights not to be updated when backpropagating. This in turn leads to stagnated learning. Other activation functions such as the sigmoid has exponential terms that makes is much more vulnerable to *vanishing gradient* issues. \n","\n","The last layer uses the softmax activation function, which transforms the input values into values between 0 and 1, hence $x_{ij} \\in [0,1]$, and returns a vector of the probability distribution for each class. The softmax function will in this purpose return the value with the highest probability that will be classified as one of the integers marked in the num_classes binary matrix.\n","\n","The number of parameters used in the network is the number of weights and the number of biases for each layer: $64^2 + 64*10 + 2 = 4738$ (the hyperparameters are the learning rate, batch size and number of epochs).\n","\n","The input layers have the dimensions 64. This is because the set of pixels on the pictures are 28x28 which is 784. This number is large and is reduced to 64 by clustering some of the pixels together. The output layer is 10 because the pictures are classified in 10 different classes, in this case the integers from 0-9.\n","\n","### b)\n","The loss function used to train the network is categorical cross entropy, expressed mathematically as \n","$$\n","C = -\\sum_{1}^{num\\_classes} y_i·\\log ŷ_i,\n","$$\n","where $ŷ_i$ is the i:th scalar value of the model output and $y_i$ is the scalar value of the label corresponding to the output.\n","\n","In order to explain how to interpret this mathematical definition, we give a simple example. Take two arrays; the first corresponding to the model output after propagating one image through the network, the second the image label data:\n","$$\n","S = \n","\\begin{bmatrix}\n","0.7 \\\\ 0.2 \\\\ 0.05 \\\\ 0.05\n","\\end{bmatrix}\\quad\\quad\\quad\n","L = \\begin{bmatrix}\n","1.0 \\\\ 0.0 \\\\ 0.0 \\\\ 0.0\n","\\end{bmatrix}.\n","$$\n","The first element of S is $ŷ_0$, and the first element of L is $y_0$. Inserting these into the cost function gives the first term of the sum. This term is $1.0·\\log(0.7)$ which is a negative number. Continuing for the remaining elements of both arrays, we compute a sum where the values of each term lie between $[-\\infty, 0]$. The negative term before the sum makes sure that the value of the cost function is positive and it is thus lower bounded, meaning that there exists a global minimum. Basically, each term is multiplied by the scalar value of the label corresponding to the image. For our first term, the first element of array L indicates that this is the true class of the image, and this scalar value is then weighted by the corresponding logaritmized prediction probability. If the probability tends to 1, the cost for this term tends to zero, otherwise there is a cost associated with it. Conversely, if the probability tends to zero the cost tends to infinity.\n","\n","It is appropriate for the problem because for each image we classify, the loss function is a measure of the error of the classification. When classifying the next image, the weights are changed by optimization of the loss function. So for each image we classify, we will get more accurate weight, hence improving the classification of the integers."],"metadata":{"id":"gNTD1djclu0q"}},{"cell_type":"markdown","source":["### c)"],"metadata":{"id":"lmXRcYbrOlab"}},{"cell_type":"code","source":["fit_info = model.fit(x_train, y_train,\n","           batch_size=batch_size,\n","           epochs=epochs,\n","           verbose=1,\n","           validation_data=(x_test, y_test))\n","score = model.evaluate(x_test, y_test, verbose=0)\n","print('Test loss: {}, Test accuracy {}'.format(score[0], score[1]))\n","\n","plt.plot(fit_info.history['accuracy'])\n","plt.plot(fit_info.history['val_accuracy'])\n","plt.title('Integer number prediction')\n","plt.ylabel('Accuracy')\n","plt.xlabel('Epoch')\n","plt.legend(['Training set', 'Test set'], loc='lower right')\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":660},"id":"HRizBufwOuWi","executionInfo":{"status":"ok","timestamp":1639646374429,"user_tz":-60,"elapsed":30894,"user":{"displayName":"Carl Hjalmarsson","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjPhXRyxfUmz6QECuK-KbhNTYdiIjr8547K5LaklQ=s64","userId":"03986481713830842027"}},"outputId":"45cf5170-2ef7-4ded-facc-2a6c4da2f905"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","469/469 [==============================] - 7s 9ms/step - loss: 0.4558 - accuracy: 0.8715 - val_loss: 0.2640 - val_accuracy: 0.9209\n","Epoch 2/10\n","469/469 [==============================] - 4s 8ms/step - loss: 0.2251 - accuracy: 0.9345 - val_loss: 0.1882 - val_accuracy: 0.9428\n","Epoch 3/10\n","469/469 [==============================] - 3s 7ms/step - loss: 0.1753 - accuracy: 0.9486 - val_loss: 0.1627 - val_accuracy: 0.9518\n","Epoch 4/10\n","469/469 [==============================] - 2s 5ms/step - loss: 0.1454 - accuracy: 0.9571 - val_loss: 0.1417 - val_accuracy: 0.9570\n","Epoch 5/10\n","469/469 [==============================] - 2s 5ms/step - loss: 0.1232 - accuracy: 0.9644 - val_loss: 0.1283 - val_accuracy: 0.9617\n","Epoch 6/10\n","469/469 [==============================] - 2s 5ms/step - loss: 0.1071 - accuracy: 0.9687 - val_loss: 0.1111 - val_accuracy: 0.9661\n","Epoch 7/10\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0957 - accuracy: 0.9717 - val_loss: 0.1030 - val_accuracy: 0.9683\n","Epoch 8/10\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0863 - accuracy: 0.9750 - val_loss: 0.1015 - val_accuracy: 0.9695\n","Epoch 9/10\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0785 - accuracy: 0.9769 - val_loss: 0.1000 - val_accuracy: 0.9686\n","Epoch 10/10\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0710 - accuracy: 0.9793 - val_loss: 0.0915 - val_accuracy: 0.9717\n","Test loss: 0.09154469519853592, Test accuracy 0.9717000126838684\n"]},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":["### d)"],"metadata":{"id":"uvJSvYIOU8P9"}},{"cell_type":"code","source":["## Define model ##\n","epochs = 40\n","w_decay = np.linspace(1e-6, 1e-3, 5)\n","replicates = 3\n","\n","val_accuracy = np.zeros((5,3))\n","mean = np.zeros(5)\n","std = np.zeros(5)\n","\n","def build_model(kernel_regularizer):\n","  model = Sequential()\n","  model.add(Flatten())\n","  model.add(Dense(500, kernel_regularizer=kernel_regularizer, activation = 'relu'))\n","  model.add(Dense(300, kernel_regularizer=kernel_regularizer, activation = 'relu'))\n","  model.add(Dense(num_classes, activation='softmax'))\n","\n","  model.compile(loss=tf.keras.losses.categorical_crossentropy,\n","                optimizer=tf.keras.optimizers.SGD(lr = 0.1),\n","          metrics=['accuracy'])\n","  return model\n","  \n","\n","for i in range(len(w_decay)):\n","  kernel_regularizer = tf.keras.regularizers.l2(w_decay[i])\n","  for j in range(replicates):\n","    model = build_model(kernel_regularizer)\n","    fit_info = model.fit(x_train, y_train,\n","              batch_size=batch_size,\n","              epochs=epochs,\n","              verbose=1,\n","              validation_data=(x_test, y_test))\n","    score = model.evaluate(x_test, y_test, verbose=0)\n","    val_accuracy[i, j] = score[1]\n","\n","  #print('Test loss: {}, Test accuracy {}'.format(score[0], score[1]))"],"metadata":{"id":"fL00BZ3bU7FO","colab":{"base_uri":"https://localhost:8080/"},"outputId":"bc0f7356-7c93-4bc8-9a7a-423a7cd6c0c9","executionInfo":{"status":"ok","timestamp":1639648486083,"user_tz":-60,"elapsed":1860123,"user":{"displayName":"Carl Hjalmarsson","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjPhXRyxfUmz6QECuK-KbhNTYdiIjr8547K5LaklQ=s64","userId":"03986481713830842027"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super(SGD, self).__init__(name, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.3951 - accuracy: 0.8896 - val_loss: 0.2099 - val_accuracy: 0.9397\n","Epoch 2/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1874 - accuracy: 0.9462 - val_loss: 0.1553 - val_accuracy: 0.9535\n","Epoch 3/40\n","469/469 [==============================] - 3s 5ms/step - loss: 0.1372 - accuracy: 0.9604 - val_loss: 0.1223 - val_accuracy: 0.9631\n","Epoch 4/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1084 - accuracy: 0.9686 - val_loss: 0.1104 - val_accuracy: 0.9658\n","Epoch 5/40\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0882 - accuracy: 0.9752 - val_loss: 0.0974 - val_accuracy: 0.9698\n","Epoch 6/40\n","469/469 [==============================] - 3s 5ms/step - loss: 0.0746 - accuracy: 0.9791 - val_loss: 0.0876 - val_accuracy: 0.9728\n","Epoch 7/40\n","469/469 [==============================] - 3s 5ms/step - loss: 0.0631 - accuracy: 0.9819 - val_loss: 0.0773 - val_accuracy: 0.9762\n","Epoch 8/40\n","469/469 [==============================] - 3s 5ms/step - loss: 0.0542 - accuracy: 0.9847 - val_loss: 0.0735 - val_accuracy: 0.9780\n","Epoch 9/40\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0466 - accuracy: 0.9876 - val_loss: 0.0755 - val_accuracy: 0.9767\n","Epoch 10/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0409 - accuracy: 0.9891 - val_loss: 0.0686 - val_accuracy: 0.9790\n","Epoch 11/40\n","469/469 [==============================] - 3s 5ms/step - loss: 0.0354 - accuracy: 0.9908 - val_loss: 0.0729 - val_accuracy: 0.9765\n","Epoch 12/40\n","469/469 [==============================] - 3s 5ms/step - loss: 0.0311 - accuracy: 0.9924 - val_loss: 0.0660 - val_accuracy: 0.9789\n","Epoch 13/40\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0276 - accuracy: 0.9934 - val_loss: 0.0677 - val_accuracy: 0.9781\n","Epoch 14/40\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0240 - accuracy: 0.9947 - val_loss: 0.0656 - val_accuracy: 0.9795\n","Epoch 15/40\n","469/469 [==============================] - 3s 5ms/step - loss: 0.0210 - accuracy: 0.9958 - val_loss: 0.0638 - val_accuracy: 0.9802\n","Epoch 16/40\n","469/469 [==============================] - 3s 5ms/step - loss: 0.0184 - accuracy: 0.9965 - val_loss: 0.0800 - val_accuracy: 0.9750\n","Epoch 17/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0163 - accuracy: 0.9973 - val_loss: 0.0611 - val_accuracy: 0.9803\n","Epoch 18/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0142 - accuracy: 0.9980 - val_loss: 0.0624 - val_accuracy: 0.9801\n","Epoch 19/40\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0126 - accuracy: 0.9984 - val_loss: 0.0631 - val_accuracy: 0.9797\n","Epoch 20/40\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0112 - accuracy: 0.9989 - val_loss: 0.0609 - val_accuracy: 0.9812\n","Epoch 21/40\n","469/469 [==============================] - 3s 5ms/step - loss: 0.0102 - accuracy: 0.9990 - val_loss: 0.0632 - val_accuracy: 0.9803\n","Epoch 22/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0091 - accuracy: 0.9992 - val_loss: 0.0629 - val_accuracy: 0.9805\n","Epoch 23/40\n","469/469 [==============================] - 3s 5ms/step - loss: 0.0083 - accuracy: 0.9994 - val_loss: 0.0620 - val_accuracy: 0.9807\n","Epoch 24/40\n","469/469 [==============================] - 3s 5ms/step - loss: 0.0075 - accuracy: 0.9994 - val_loss: 0.0645 - val_accuracy: 0.9803\n","Epoch 25/40\n","469/469 [==============================] - 3s 5ms/step - loss: 0.0069 - accuracy: 0.9996 - val_loss: 0.0628 - val_accuracy: 0.9810\n","Epoch 26/40\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0063 - accuracy: 0.9997 - val_loss: 0.0637 - val_accuracy: 0.9808\n","Epoch 27/40\n","469/469 [==============================] - 3s 5ms/step - loss: 0.0059 - accuracy: 0.9997 - val_loss: 0.0634 - val_accuracy: 0.9808\n","Epoch 28/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0054 - accuracy: 0.9998 - val_loss: 0.0627 - val_accuracy: 0.9815\n","Epoch 29/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0050 - accuracy: 0.9999 - val_loss: 0.0636 - val_accuracy: 0.9804\n","Epoch 30/40\n","469/469 [==============================] - 3s 5ms/step - loss: 0.0047 - accuracy: 0.9999 - val_loss: 0.0634 - val_accuracy: 0.9808\n","Epoch 31/40\n","469/469 [==============================] - 3s 5ms/step - loss: 0.0044 - accuracy: 0.9999 - val_loss: 0.0651 - val_accuracy: 0.9807\n","Epoch 32/40\n","469/469 [==============================] - 3s 5ms/step - loss: 0.0042 - accuracy: 0.9999 - val_loss: 0.0659 - val_accuracy: 0.9808\n","Epoch 33/40\n","469/469 [==============================] - 3s 5ms/step - loss: 0.0040 - accuracy: 0.9999 - val_loss: 0.0649 - val_accuracy: 0.9809\n","Epoch 34/40\n","469/469 [==============================] - 3s 5ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0644 - val_accuracy: 0.9807\n","Epoch 35/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0648 - val_accuracy: 0.9809\n","Epoch 36/40\n","469/469 [==============================] - 3s 5ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0649 - val_accuracy: 0.9816\n","Epoch 37/40\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0659 - val_accuracy: 0.9814\n","Epoch 38/40\n","469/469 [==============================] - 3s 5ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0658 - val_accuracy: 0.9811\n","Epoch 39/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0666 - val_accuracy: 0.9810\n","Epoch 40/40\n","469/469 [==============================] - 3s 5ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0655 - val_accuracy: 0.9813\n","Epoch 1/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.4056 - accuracy: 0.8870 - val_loss: 0.2378 - val_accuracy: 0.9280\n","Epoch 2/40\n","469/469 [==============================] - 3s 5ms/step - loss: 0.1910 - accuracy: 0.9457 - val_loss: 0.1547 - val_accuracy: 0.9545\n","Epoch 3/40\n","469/469 [==============================] - 3s 5ms/step - loss: 0.1400 - accuracy: 0.9593 - val_loss: 0.1223 - val_accuracy: 0.9640\n","Epoch 4/40\n","469/469 [==============================] - 3s 5ms/step - loss: 0.1101 - accuracy: 0.9688 - val_loss: 0.1071 - val_accuracy: 0.9676\n","Epoch 5/40\n","469/469 [==============================] - 3s 5ms/step - loss: 0.0915 - accuracy: 0.9737 - val_loss: 0.0969 - val_accuracy: 0.9698\n","Epoch 6/40\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0764 - accuracy: 0.9786 - val_loss: 0.0880 - val_accuracy: 0.9747\n","Epoch 7/40\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0649 - accuracy: 0.9819 - val_loss: 0.0787 - val_accuracy: 0.9759\n","Epoch 8/40\n","469/469 [==============================] - 3s 5ms/step - loss: 0.0557 - accuracy: 0.9846 - val_loss: 0.1122 - val_accuracy: 0.9653\n","Epoch 9/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0481 - accuracy: 0.9876 - val_loss: 0.0758 - val_accuracy: 0.9754\n","Epoch 10/40\n","469/469 [==============================] - 3s 5ms/step - loss: 0.0418 - accuracy: 0.9893 - val_loss: 0.0730 - val_accuracy: 0.9779\n","Epoch 11/40\n","469/469 [==============================] - 3s 5ms/step - loss: 0.0365 - accuracy: 0.9906 - val_loss: 0.0688 - val_accuracy: 0.9787\n","Epoch 12/40\n","469/469 [==============================] - 3s 5ms/step - loss: 0.0326 - accuracy: 0.9919 - val_loss: 0.0642 - val_accuracy: 0.9804\n","Epoch 13/40\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0279 - accuracy: 0.9936 - val_loss: 0.0740 - val_accuracy: 0.9770\n","Epoch 14/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0250 - accuracy: 0.9943 - val_loss: 0.0658 - val_accuracy: 0.9790\n","Epoch 15/40\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0221 - accuracy: 0.9954 - val_loss: 0.0659 - val_accuracy: 0.9787\n","Epoch 16/40\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0194 - accuracy: 0.9966 - val_loss: 0.0623 - val_accuracy: 0.9801\n","Epoch 17/40\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0170 - accuracy: 0.9970 - val_loss: 0.0687 - val_accuracy: 0.9796\n","Epoch 18/40\n","469/469 [==============================] - 3s 5ms/step - loss: 0.0150 - accuracy: 0.9978 - val_loss: 0.0609 - val_accuracy: 0.9804\n","Epoch 19/40\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0132 - accuracy: 0.9981 - val_loss: 0.0630 - val_accuracy: 0.9796\n","Epoch 20/40\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0118 - accuracy: 0.9986 - val_loss: 0.0613 - val_accuracy: 0.9812\n","Epoch 21/40\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0107 - accuracy: 0.9987 - val_loss: 0.0610 - val_accuracy: 0.9814\n","Epoch 22/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0096 - accuracy: 0.9992 - val_loss: 0.0605 - val_accuracy: 0.9813\n","Epoch 23/40\n","469/469 [==============================] - 3s 5ms/step - loss: 0.0088 - accuracy: 0.9992 - val_loss: 0.0609 - val_accuracy: 0.9814\n","Epoch 24/40\n","469/469 [==============================] - 3s 5ms/step - loss: 0.0078 - accuracy: 0.9995 - val_loss: 0.0617 - val_accuracy: 0.9813\n","Epoch 25/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0071 - accuracy: 0.9996 - val_loss: 0.0622 - val_accuracy: 0.9814\n","Epoch 26/40\n","469/469 [==============================] - 3s 5ms/step - loss: 0.0064 - accuracy: 0.9997 - val_loss: 0.0613 - val_accuracy: 0.9817\n","Epoch 27/40\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0060 - accuracy: 0.9998 - val_loss: 0.0651 - val_accuracy: 0.9816\n","Epoch 28/40\n","469/469 [==============================] - 3s 5ms/step - loss: 0.0055 - accuracy: 0.9998 - val_loss: 0.0622 - val_accuracy: 0.9820\n","Epoch 29/40\n","469/469 [==============================] - 3s 5ms/step - loss: 0.0052 - accuracy: 0.9999 - val_loss: 0.0622 - val_accuracy: 0.9813\n","Epoch 30/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0049 - accuracy: 0.9999 - val_loss: 0.0630 - val_accuracy: 0.9817\n","Epoch 31/40\n","469/469 [==============================] - 3s 5ms/step - loss: 0.0046 - accuracy: 0.9999 - val_loss: 0.0634 - val_accuracy: 0.9815\n","Epoch 32/40\n","469/469 [==============================] - 3s 5ms/step - loss: 0.0043 - accuracy: 0.9999 - val_loss: 0.0638 - val_accuracy: 0.9814\n","Epoch 33/40\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0041 - accuracy: 0.9999 - val_loss: 0.0635 - val_accuracy: 0.9818\n","Epoch 34/40\n","469/469 [==============================] - 3s 5ms/step - loss: 0.0039 - accuracy: 0.9999 - val_loss: 0.0629 - val_accuracy: 0.9819\n","Epoch 35/40\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0643 - val_accuracy: 0.9817\n","Epoch 36/40\n","469/469 [==============================] - 3s 5ms/step - loss: 0.0036 - accuracy: 0.9999 - val_loss: 0.0639 - val_accuracy: 0.9820\n","Epoch 37/40\n","469/469 [==============================] - 3s 5ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0657 - val_accuracy: 0.9821\n","Epoch 38/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0651 - val_accuracy: 0.9821\n","Epoch 39/40\n","469/469 [==============================] - 3s 5ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0655 - val_accuracy: 0.9825\n","Epoch 40/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0657 - val_accuracy: 0.9823\n","Epoch 1/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.3981 - accuracy: 0.8905 - val_loss: 0.2139 - val_accuracy: 0.9367\n","Epoch 2/40\n","469/469 [==============================] - 2s 5ms/step - loss: 0.1873 - accuracy: 0.9460 - val_loss: 0.1542 - val_accuracy: 0.9554\n","Epoch 3/40\n","469/469 [==============================] - 3s 5ms/step - loss: 0.1363 - accuracy: 0.9609 - val_loss: 0.1327 - val_accuracy: 0.9611\n","Epoch 4/40\n","469/469 [==============================] - 3s 5ms/step - loss: 0.1077 - accuracy: 0.9686 - val_loss: 0.1032 - val_accuracy: 0.9686\n","Epoch 5/40\n","469/469 [==============================] - 3s 5ms/step - loss: 0.0879 - accuracy: 0.9747 - val_loss: 0.0919 - val_accuracy: 0.9719\n","Epoch 6/40\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0731 - accuracy: 0.9795 - val_loss: 0.0820 - val_accuracy: 0.9760\n","Epoch 7/40\n","469/469 [==============================] - 3s 5ms/step - loss: 0.0623 - accuracy: 0.9828 - val_loss: 0.0841 - val_accuracy: 0.9751\n","Epoch 8/40\n","469/469 [==============================] - 3s 5ms/step - loss: 0.0541 - accuracy: 0.9847 - val_loss: 0.0742 - val_accuracy: 0.9769\n","Epoch 9/40\n","469/469 [==============================] - 3s 5ms/step - loss: 0.0465 - accuracy: 0.9870 - val_loss: 0.0730 - val_accuracy: 0.9763\n","Epoch 10/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0406 - accuracy: 0.9888 - val_loss: 0.0674 - val_accuracy: 0.9804\n","Epoch 11/40\n","469/469 [==============================] - 3s 5ms/step - loss: 0.0349 - accuracy: 0.9909 - val_loss: 0.0643 - val_accuracy: 0.9797\n","Epoch 12/40\n","469/469 [==============================] - 3s 5ms/step - loss: 0.0311 - accuracy: 0.9921 - val_loss: 0.0693 - val_accuracy: 0.9782\n","Epoch 13/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0270 - accuracy: 0.9936 - val_loss: 0.0634 - val_accuracy: 0.9805\n","Epoch 14/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0236 - accuracy: 0.9949 - val_loss: 0.0644 - val_accuracy: 0.9793\n","Epoch 15/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0204 - accuracy: 0.9958 - val_loss: 0.0635 - val_accuracy: 0.9811\n","Epoch 16/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0183 - accuracy: 0.9965 - val_loss: 0.0614 - val_accuracy: 0.9803\n","Epoch 17/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0160 - accuracy: 0.9976 - val_loss: 0.0643 - val_accuracy: 0.9797\n","Epoch 18/40\n","469/469 [==============================] - 3s 5ms/step - loss: 0.0141 - accuracy: 0.9978 - val_loss: 0.0617 - val_accuracy: 0.9816\n","Epoch 19/40\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0125 - accuracy: 0.9984 - val_loss: 0.0613 - val_accuracy: 0.9804\n","Epoch 20/40\n","469/469 [==============================] - 3s 5ms/step - loss: 0.0111 - accuracy: 0.9989 - val_loss: 0.0621 - val_accuracy: 0.9815\n","Epoch 21/40\n","469/469 [==============================] - 3s 5ms/step - loss: 0.0099 - accuracy: 0.9990 - val_loss: 0.0633 - val_accuracy: 0.9810\n","Epoch 22/40\n","469/469 [==============================] - 3s 5ms/step - loss: 0.0088 - accuracy: 0.9993 - val_loss: 0.0617 - val_accuracy: 0.9821\n","Epoch 23/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0081 - accuracy: 0.9995 - val_loss: 0.0643 - val_accuracy: 0.9806\n","Epoch 24/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0073 - accuracy: 0.9995 - val_loss: 0.0639 - val_accuracy: 0.9820\n","Epoch 25/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0066 - accuracy: 0.9997 - val_loss: 0.0639 - val_accuracy: 0.9811\n","Epoch 26/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0062 - accuracy: 0.9997 - val_loss: 0.0623 - val_accuracy: 0.9813\n","Epoch 27/40\n","469/469 [==============================] - 3s 5ms/step - loss: 0.0057 - accuracy: 0.9998 - val_loss: 0.0636 - val_accuracy: 0.9819\n","Epoch 28/40\n","469/469 [==============================] - 3s 5ms/step - loss: 0.0052 - accuracy: 0.9999 - val_loss: 0.0630 - val_accuracy: 0.9819\n","Epoch 29/40\n","469/469 [==============================] - 3s 5ms/step - loss: 0.0049 - accuracy: 0.9999 - val_loss: 0.0638 - val_accuracy: 0.9817\n","Epoch 30/40\n","469/469 [==============================] - 3s 5ms/step - loss: 0.0046 - accuracy: 0.9999 - val_loss: 0.0634 - val_accuracy: 0.9816\n","Epoch 31/40\n","469/469 [==============================] - 3s 5ms/step - loss: 0.0044 - accuracy: 0.9999 - val_loss: 0.0653 - val_accuracy: 0.9815\n","Epoch 32/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0041 - accuracy: 0.9999 - val_loss: 0.0646 - val_accuracy: 0.9815\n","Epoch 33/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0650 - val_accuracy: 0.9815\n","Epoch 34/40\n","469/469 [==============================] - 3s 5ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0649 - val_accuracy: 0.9815\n","Epoch 35/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0648 - val_accuracy: 0.9817\n","Epoch 36/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0654 - val_accuracy: 0.9819\n","Epoch 37/40\n","469/469 [==============================] - 3s 5ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0652 - val_accuracy: 0.9817\n","Epoch 38/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0663 - val_accuracy: 0.9815\n","Epoch 39/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0669 - val_accuracy: 0.9816\n","Epoch 40/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0664 - val_accuracy: 0.9820\n","Epoch 1/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.6508 - accuracy: 0.8870 - val_loss: 0.4614 - val_accuracy: 0.9391\n","Epoch 2/40\n","469/469 [==============================] - 3s 5ms/step - loss: 0.4288 - accuracy: 0.9458 - val_loss: 0.4103 - val_accuracy: 0.9463\n","Epoch 3/40\n","469/469 [==============================] - 3s 5ms/step - loss: 0.3719 - accuracy: 0.9599 - val_loss: 0.3499 - val_accuracy: 0.9629\n","Epoch 4/40\n","469/469 [==============================] - 3s 5ms/step - loss: 0.3352 - accuracy: 0.9685 - val_loss: 0.3229 - val_accuracy: 0.9682\n","Epoch 5/40\n","469/469 [==============================] - 2s 5ms/step - loss: 0.3085 - accuracy: 0.9740 - val_loss: 0.3073 - val_accuracy: 0.9708\n","Epoch 6/40\n","469/469 [==============================] - 2s 5ms/step - loss: 0.2875 - accuracy: 0.9776 - val_loss: 0.2919 - val_accuracy: 0.9745\n","Epoch 7/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.2695 - accuracy: 0.9812 - val_loss: 0.2782 - val_accuracy: 0.9757\n","Epoch 8/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.2545 - accuracy: 0.9836 - val_loss: 0.2653 - val_accuracy: 0.9764\n","Epoch 9/40\n","469/469 [==============================] - 2s 5ms/step - loss: 0.2400 - accuracy: 0.9862 - val_loss: 0.2593 - val_accuracy: 0.9779\n","Epoch 10/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.2283 - accuracy: 0.9876 - val_loss: 0.2517 - val_accuracy: 0.9782\n","Epoch 11/40\n","469/469 [==============================] - 3s 5ms/step - loss: 0.2176 - accuracy: 0.9889 - val_loss: 0.2398 - val_accuracy: 0.9786\n","Epoch 12/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.2080 - accuracy: 0.9899 - val_loss: 0.2327 - val_accuracy: 0.9790\n","Epoch 13/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1983 - accuracy: 0.9912 - val_loss: 0.2259 - val_accuracy: 0.9793\n","Epoch 14/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1891 - accuracy: 0.9927 - val_loss: 0.2165 - val_accuracy: 0.9813\n","Epoch 15/40\n","469/469 [==============================] - 3s 5ms/step - loss: 0.1814 - accuracy: 0.9932 - val_loss: 0.2122 - val_accuracy: 0.9798\n","Epoch 16/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1739 - accuracy: 0.9941 - val_loss: 0.2062 - val_accuracy: 0.9811\n","Epoch 17/40\n","469/469 [==============================] - 3s 5ms/step - loss: 0.1667 - accuracy: 0.9950 - val_loss: 0.2037 - val_accuracy: 0.9785\n","Epoch 18/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1600 - accuracy: 0.9955 - val_loss: 0.1997 - val_accuracy: 0.9803\n","Epoch 19/40\n","469/469 [==============================] - 3s 5ms/step - loss: 0.1538 - accuracy: 0.9959 - val_loss: 0.1934 - val_accuracy: 0.9798\n","Epoch 20/40\n","469/469 [==============================] - 3s 5ms/step - loss: 0.1481 - accuracy: 0.9962 - val_loss: 0.1860 - val_accuracy: 0.9816\n","Epoch 21/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1428 - accuracy: 0.9966 - val_loss: 0.1787 - val_accuracy: 0.9818\n","Epoch 22/40\n","469/469 [==============================] - 3s 5ms/step - loss: 0.1369 - accuracy: 0.9973 - val_loss: 0.1790 - val_accuracy: 0.9804\n","Epoch 23/40\n","469/469 [==============================] - 3s 5ms/step - loss: 0.1318 - accuracy: 0.9978 - val_loss: 0.1716 - val_accuracy: 0.9817\n","Epoch 24/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1273 - accuracy: 0.9979 - val_loss: 0.1685 - val_accuracy: 0.9810\n","Epoch 25/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1228 - accuracy: 0.9981 - val_loss: 0.1681 - val_accuracy: 0.9803\n","Epoch 26/40\n","469/469 [==============================] - 2s 5ms/step - loss: 0.1187 - accuracy: 0.9983 - val_loss: 0.1610 - val_accuracy: 0.9809\n","Epoch 27/40\n","469/469 [==============================] - 2s 5ms/step - loss: 0.1149 - accuracy: 0.9984 - val_loss: 0.1554 - val_accuracy: 0.9810\n","Epoch 28/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1110 - accuracy: 0.9985 - val_loss: 0.1626 - val_accuracy: 0.9790\n","Epoch 29/40\n","469/469 [==============================] - 3s 5ms/step - loss: 0.1073 - accuracy: 0.9989 - val_loss: 0.1536 - val_accuracy: 0.9805\n","Epoch 30/40\n","469/469 [==============================] - 3s 5ms/step - loss: 0.1037 - accuracy: 0.9990 - val_loss: 0.1482 - val_accuracy: 0.9809\n","Epoch 31/40\n","469/469 [==============================] - 3s 5ms/step - loss: 0.1006 - accuracy: 0.9990 - val_loss: 0.1447 - val_accuracy: 0.9815\n","Epoch 32/40\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0975 - accuracy: 0.9991 - val_loss: 0.1498 - val_accuracy: 0.9802\n","Epoch 33/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0944 - accuracy: 0.9991 - val_loss: 0.1419 - val_accuracy: 0.9810\n","Epoch 34/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0914 - accuracy: 0.9994 - val_loss: 0.1366 - val_accuracy: 0.9812\n","Epoch 35/40\n","469/469 [==============================] - 3s 5ms/step - loss: 0.0888 - accuracy: 0.9993 - val_loss: 0.1331 - val_accuracy: 0.9822\n","Epoch 36/40\n","469/469 [==============================] - 3s 5ms/step - loss: 0.0862 - accuracy: 0.9995 - val_loss: 0.1327 - val_accuracy: 0.9816\n","Epoch 37/40\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0840 - accuracy: 0.9994 - val_loss: 0.1303 - val_accuracy: 0.9815\n","Epoch 38/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0816 - accuracy: 0.9995 - val_loss: 0.1291 - val_accuracy: 0.9807\n","Epoch 39/40\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0791 - accuracy: 0.9995 - val_loss: 0.1245 - val_accuracy: 0.9819\n","Epoch 40/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0769 - accuracy: 0.9996 - val_loss: 0.1239 - val_accuracy: 0.9819\n","Epoch 1/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.6588 - accuracy: 0.8849 - val_loss: 0.4663 - val_accuracy: 0.9385\n","Epoch 2/40\n","469/469 [==============================] - 2s 5ms/step - loss: 0.4358 - accuracy: 0.9435 - val_loss: 0.3976 - val_accuracy: 0.9532\n","Epoch 3/40\n","469/469 [==============================] - 2s 5ms/step - loss: 0.3752 - accuracy: 0.9587 - val_loss: 0.3557 - val_accuracy: 0.9627\n","Epoch 4/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.3377 - accuracy: 0.9679 - val_loss: 0.3360 - val_accuracy: 0.9651\n","Epoch 5/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.3100 - accuracy: 0.9736 - val_loss: 0.3227 - val_accuracy: 0.9653\n","Epoch 6/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.2881 - accuracy: 0.9776 - val_loss: 0.2919 - val_accuracy: 0.9728\n","Epoch 7/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.2703 - accuracy: 0.9809 - val_loss: 0.2835 - val_accuracy: 0.9747\n","Epoch 8/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.2545 - accuracy: 0.9834 - val_loss: 0.2658 - val_accuracy: 0.9775\n","Epoch 9/40\n","469/469 [==============================] - 3s 5ms/step - loss: 0.2409 - accuracy: 0.9857 - val_loss: 0.2629 - val_accuracy: 0.9746\n","Epoch 10/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.2285 - accuracy: 0.9874 - val_loss: 0.2473 - val_accuracy: 0.9786\n","Epoch 11/40\n","469/469 [==============================] - 3s 5ms/step - loss: 0.2174 - accuracy: 0.9894 - val_loss: 0.2444 - val_accuracy: 0.9773\n","Epoch 12/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.2075 - accuracy: 0.9903 - val_loss: 0.2338 - val_accuracy: 0.9792\n","Epoch 13/40\n","469/469 [==============================] - 2s 5ms/step - loss: 0.1980 - accuracy: 0.9912 - val_loss: 0.2280 - val_accuracy: 0.9797\n","Epoch 14/40\n","469/469 [==============================] - 2s 5ms/step - loss: 0.1888 - accuracy: 0.9927 - val_loss: 0.2254 - val_accuracy: 0.9778\n","Epoch 15/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1815 - accuracy: 0.9933 - val_loss: 0.2129 - val_accuracy: 0.9797\n","Epoch 16/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1730 - accuracy: 0.9948 - val_loss: 0.2078 - val_accuracy: 0.9793\n","Epoch 17/40\n","469/469 [==============================] - 2s 5ms/step - loss: 0.1662 - accuracy: 0.9949 - val_loss: 0.1996 - val_accuracy: 0.9802\n","Epoch 18/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1596 - accuracy: 0.9960 - val_loss: 0.1969 - val_accuracy: 0.9806\n","Epoch 19/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1534 - accuracy: 0.9962 - val_loss: 0.1889 - val_accuracy: 0.9809\n","Epoch 20/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1477 - accuracy: 0.9969 - val_loss: 0.1850 - val_accuracy: 0.9809\n","Epoch 21/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1420 - accuracy: 0.9973 - val_loss: 0.1800 - val_accuracy: 0.9802\n","Epoch 22/40\n","469/469 [==============================] - 3s 5ms/step - loss: 0.1369 - accuracy: 0.9974 - val_loss: 0.1746 - val_accuracy: 0.9813\n","Epoch 23/40\n","469/469 [==============================] - 3s 5ms/step - loss: 0.1318 - accuracy: 0.9977 - val_loss: 0.1702 - val_accuracy: 0.9808\n","Epoch 24/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1272 - accuracy: 0.9981 - val_loss: 0.1682 - val_accuracy: 0.9814\n","Epoch 25/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1229 - accuracy: 0.9981 - val_loss: 0.1633 - val_accuracy: 0.9827\n","Epoch 26/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1187 - accuracy: 0.9985 - val_loss: 0.1586 - val_accuracy: 0.9814\n","Epoch 27/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1145 - accuracy: 0.9987 - val_loss: 0.1543 - val_accuracy: 0.9827\n","Epoch 28/40\n","469/469 [==============================] - 3s 5ms/step - loss: 0.1108 - accuracy: 0.9987 - val_loss: 0.1572 - val_accuracy: 0.9809\n","Epoch 29/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1071 - accuracy: 0.9988 - val_loss: 0.1507 - val_accuracy: 0.9814\n","Epoch 30/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1039 - accuracy: 0.9989 - val_loss: 0.1474 - val_accuracy: 0.9813\n","Epoch 31/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1004 - accuracy: 0.9991 - val_loss: 0.1433 - val_accuracy: 0.9822\n","Epoch 32/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0973 - accuracy: 0.9992 - val_loss: 0.1427 - val_accuracy: 0.9810\n","Epoch 33/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0942 - accuracy: 0.9993 - val_loss: 0.1395 - val_accuracy: 0.9819\n","Epoch 34/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0915 - accuracy: 0.9992 - val_loss: 0.1341 - val_accuracy: 0.9827\n","Epoch 35/40\n","469/469 [==============================] - 3s 5ms/step - loss: 0.0888 - accuracy: 0.9992 - val_loss: 0.1317 - val_accuracy: 0.9819\n","Epoch 36/40\n","469/469 [==============================] - 3s 5ms/step - loss: 0.0862 - accuracy: 0.9994 - val_loss: 0.1369 - val_accuracy: 0.9801\n","Epoch 37/40\n","469/469 [==============================] - 3s 5ms/step - loss: 0.0838 - accuracy: 0.9995 - val_loss: 0.1267 - val_accuracy: 0.9823\n","Epoch 38/40\n","469/469 [==============================] - 3s 5ms/step - loss: 0.0813 - accuracy: 0.9995 - val_loss: 0.1250 - val_accuracy: 0.9830\n","Epoch 39/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0792 - accuracy: 0.9995 - val_loss: 0.1240 - val_accuracy: 0.9819\n","Epoch 40/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0770 - accuracy: 0.9994 - val_loss: 0.1221 - val_accuracy: 0.9831\n","Epoch 1/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.6617 - accuracy: 0.8856 - val_loss: 0.4764 - val_accuracy: 0.9326\n","Epoch 2/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.4348 - accuracy: 0.9436 - val_loss: 0.3953 - val_accuracy: 0.9527\n","Epoch 3/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.3752 - accuracy: 0.9588 - val_loss: 0.3614 - val_accuracy: 0.9608\n","Epoch 4/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.3385 - accuracy: 0.9674 - val_loss: 0.3248 - val_accuracy: 0.9684\n","Epoch 5/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.3112 - accuracy: 0.9730 - val_loss: 0.3109 - val_accuracy: 0.9691\n","Epoch 6/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.2890 - accuracy: 0.9774 - val_loss: 0.2986 - val_accuracy: 0.9716\n","Epoch 7/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.2713 - accuracy: 0.9802 - val_loss: 0.2820 - val_accuracy: 0.9755\n","Epoch 8/40\n","469/469 [==============================] - 3s 5ms/step - loss: 0.2556 - accuracy: 0.9830 - val_loss: 0.2707 - val_accuracy: 0.9771\n","Epoch 9/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.2420 - accuracy: 0.9856 - val_loss: 0.2621 - val_accuracy: 0.9751\n","Epoch 10/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.2297 - accuracy: 0.9872 - val_loss: 0.2481 - val_accuracy: 0.9792\n","Epoch 11/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.2180 - accuracy: 0.9888 - val_loss: 0.2391 - val_accuracy: 0.9794\n","Epoch 12/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.2084 - accuracy: 0.9894 - val_loss: 0.2324 - val_accuracy: 0.9802\n","Epoch 13/40\n","469/469 [==============================] - 3s 5ms/step - loss: 0.1984 - accuracy: 0.9916 - val_loss: 0.2266 - val_accuracy: 0.9805\n","Epoch 14/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1903 - accuracy: 0.9920 - val_loss: 0.2184 - val_accuracy: 0.9799\n","Epoch 15/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1820 - accuracy: 0.9930 - val_loss: 0.2195 - val_accuracy: 0.9783\n","Epoch 16/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1742 - accuracy: 0.9941 - val_loss: 0.2095 - val_accuracy: 0.9796\n","Epoch 17/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1671 - accuracy: 0.9948 - val_loss: 0.2013 - val_accuracy: 0.9807\n","Epoch 18/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1601 - accuracy: 0.9958 - val_loss: 0.1969 - val_accuracy: 0.9811\n","Epoch 19/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1540 - accuracy: 0.9961 - val_loss: 0.1916 - val_accuracy: 0.9807\n","Epoch 20/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1481 - accuracy: 0.9966 - val_loss: 0.1900 - val_accuracy: 0.9805\n","Epoch 21/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1429 - accuracy: 0.9969 - val_loss: 0.1849 - val_accuracy: 0.9785\n","Epoch 22/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1375 - accuracy: 0.9973 - val_loss: 0.1911 - val_accuracy: 0.9763\n","Epoch 23/40\n","469/469 [==============================] - 3s 5ms/step - loss: 0.1327 - accuracy: 0.9977 - val_loss: 0.1732 - val_accuracy: 0.9814\n","Epoch 24/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1278 - accuracy: 0.9979 - val_loss: 0.1665 - val_accuracy: 0.9823\n","Epoch 25/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1233 - accuracy: 0.9982 - val_loss: 0.1631 - val_accuracy: 0.9815\n","Epoch 26/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1191 - accuracy: 0.9982 - val_loss: 0.1672 - val_accuracy: 0.9793\n","Epoch 27/40\n","469/469 [==============================] - 3s 5ms/step - loss: 0.1152 - accuracy: 0.9985 - val_loss: 0.1618 - val_accuracy: 0.9808\n","Epoch 28/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1114 - accuracy: 0.9985 - val_loss: 0.1540 - val_accuracy: 0.9824\n","Epoch 29/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1076 - accuracy: 0.9989 - val_loss: 0.1491 - val_accuracy: 0.9819\n","Epoch 30/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1040 - accuracy: 0.9990 - val_loss: 0.1459 - val_accuracy: 0.9825\n","Epoch 31/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1010 - accuracy: 0.9991 - val_loss: 0.1462 - val_accuracy: 0.9818\n","Epoch 32/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0981 - accuracy: 0.9989 - val_loss: 0.1413 - val_accuracy: 0.9819\n","Epoch 33/40\n","469/469 [==============================] - 3s 5ms/step - loss: 0.0947 - accuracy: 0.9991 - val_loss: 0.1372 - val_accuracy: 0.9824\n","Epoch 34/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0919 - accuracy: 0.9993 - val_loss: 0.1363 - val_accuracy: 0.9824\n","Epoch 35/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0892 - accuracy: 0.9993 - val_loss: 0.1343 - val_accuracy: 0.9825\n","Epoch 36/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0866 - accuracy: 0.9993 - val_loss: 0.1302 - val_accuracy: 0.9829\n","Epoch 37/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0842 - accuracy: 0.9994 - val_loss: 0.1269 - val_accuracy: 0.9831\n","Epoch 38/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0818 - accuracy: 0.9995 - val_loss: 0.1256 - val_accuracy: 0.9820\n","Epoch 39/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0795 - accuracy: 0.9994 - val_loss: 0.1268 - val_accuracy: 0.9819\n","Epoch 40/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0773 - accuracy: 0.9994 - val_loss: 0.1253 - val_accuracy: 0.9814\n","Epoch 1/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.8925 - accuracy: 0.8852 - val_loss: 0.6890 - val_accuracy: 0.9354\n","Epoch 2/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.6417 - accuracy: 0.9435 - val_loss: 0.5894 - val_accuracy: 0.9536\n","Epoch 3/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.5589 - accuracy: 0.9585 - val_loss: 0.5452 - val_accuracy: 0.9534\n","Epoch 4/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.4998 - accuracy: 0.9669 - val_loss: 0.4805 - val_accuracy: 0.9671\n","Epoch 5/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.4528 - accuracy: 0.9726 - val_loss: 0.4422 - val_accuracy: 0.9697\n","Epoch 6/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.4134 - accuracy: 0.9759 - val_loss: 0.4029 - val_accuracy: 0.9727\n","Epoch 7/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.3790 - accuracy: 0.9792 - val_loss: 0.3741 - val_accuracy: 0.9743\n","Epoch 8/40\n","469/469 [==============================] - 3s 5ms/step - loss: 0.3487 - accuracy: 0.9822 - val_loss: 0.3487 - val_accuracy: 0.9773\n","Epoch 9/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.3215 - accuracy: 0.9843 - val_loss: 0.3267 - val_accuracy: 0.9772\n","Epoch 10/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.2978 - accuracy: 0.9858 - val_loss: 0.3116 - val_accuracy: 0.9767\n","Epoch 11/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.2765 - accuracy: 0.9870 - val_loss: 0.2932 - val_accuracy: 0.9773\n","Epoch 12/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.2573 - accuracy: 0.9885 - val_loss: 0.2797 - val_accuracy: 0.9758\n","Epoch 13/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.2395 - accuracy: 0.9893 - val_loss: 0.2552 - val_accuracy: 0.9799\n","Epoch 14/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.2231 - accuracy: 0.9904 - val_loss: 0.2601 - val_accuracy: 0.9752\n","Epoch 15/40\n","469/469 [==============================] - 3s 5ms/step - loss: 0.2090 - accuracy: 0.9915 - val_loss: 0.2334 - val_accuracy: 0.9788\n","Epoch 16/40\n","469/469 [==============================] - 3s 5ms/step - loss: 0.1960 - accuracy: 0.9918 - val_loss: 0.2185 - val_accuracy: 0.9802\n","Epoch 17/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1840 - accuracy: 0.9925 - val_loss: 0.2063 - val_accuracy: 0.9817\n","Epoch 18/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1732 - accuracy: 0.9932 - val_loss: 0.1961 - val_accuracy: 0.9820\n","Epoch 19/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1632 - accuracy: 0.9936 - val_loss: 0.1907 - val_accuracy: 0.9804\n","Epoch 20/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1543 - accuracy: 0.9940 - val_loss: 0.1920 - val_accuracy: 0.9791\n","Epoch 21/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1458 - accuracy: 0.9947 - val_loss: 0.1808 - val_accuracy: 0.9771\n","Epoch 22/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1386 - accuracy: 0.9946 - val_loss: 0.1712 - val_accuracy: 0.9815\n","Epoch 23/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1314 - accuracy: 0.9955 - val_loss: 0.1692 - val_accuracy: 0.9790\n","Epoch 24/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1255 - accuracy: 0.9954 - val_loss: 0.1582 - val_accuracy: 0.9808\n","Epoch 25/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1197 - accuracy: 0.9954 - val_loss: 0.1495 - val_accuracy: 0.9818\n","Epoch 26/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1141 - accuracy: 0.9963 - val_loss: 0.1472 - val_accuracy: 0.9812\n","Epoch 27/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1088 - accuracy: 0.9967 - val_loss: 0.1410 - val_accuracy: 0.9817\n","Epoch 28/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1044 - accuracy: 0.9965 - val_loss: 0.1388 - val_accuracy: 0.9815\n","Epoch 29/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1008 - accuracy: 0.9965 - val_loss: 0.1321 - val_accuracy: 0.9827\n","Epoch 30/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0970 - accuracy: 0.9966 - val_loss: 0.1364 - val_accuracy: 0.9802\n","Epoch 31/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0940 - accuracy: 0.9968 - val_loss: 0.1283 - val_accuracy: 0.9827\n","Epoch 32/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0904 - accuracy: 0.9969 - val_loss: 0.1244 - val_accuracy: 0.9830\n","Epoch 33/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0876 - accuracy: 0.9969 - val_loss: 0.1219 - val_accuracy: 0.9829\n","Epoch 34/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0849 - accuracy: 0.9973 - val_loss: 0.1184 - val_accuracy: 0.9821\n","Epoch 35/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0818 - accuracy: 0.9975 - val_loss: 0.1163 - val_accuracy: 0.9834\n","Epoch 36/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0799 - accuracy: 0.9973 - val_loss: 0.1147 - val_accuracy: 0.9825\n","Epoch 37/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0775 - accuracy: 0.9976 - val_loss: 0.1114 - val_accuracy: 0.9821\n","Epoch 38/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0752 - accuracy: 0.9977 - val_loss: 0.1129 - val_accuracy: 0.9813\n","Epoch 39/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0734 - accuracy: 0.9978 - val_loss: 0.1116 - val_accuracy: 0.9828\n","Epoch 40/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0721 - accuracy: 0.9979 - val_loss: 0.1104 - val_accuracy: 0.9820\n","Epoch 1/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.8853 - accuracy: 0.8892 - val_loss: 0.6936 - val_accuracy: 0.9342\n","Epoch 2/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.6408 - accuracy: 0.9441 - val_loss: 0.5868 - val_accuracy: 0.9532\n","Epoch 3/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.5571 - accuracy: 0.9591 - val_loss: 0.5285 - val_accuracy: 0.9621\n","Epoch 4/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.4983 - accuracy: 0.9678 - val_loss: 0.4791 - val_accuracy: 0.9672\n","Epoch 5/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.4516 - accuracy: 0.9725 - val_loss: 0.4368 - val_accuracy: 0.9713\n","Epoch 6/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.4124 - accuracy: 0.9761 - val_loss: 0.4094 - val_accuracy: 0.9722\n","Epoch 7/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.3774 - accuracy: 0.9797 - val_loss: 0.3830 - val_accuracy: 0.9728\n","Epoch 8/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.3475 - accuracy: 0.9820 - val_loss: 0.3544 - val_accuracy: 0.9752\n","Epoch 9/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.3214 - accuracy: 0.9837 - val_loss: 0.3291 - val_accuracy: 0.9776\n","Epoch 10/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.2968 - accuracy: 0.9856 - val_loss: 0.3142 - val_accuracy: 0.9751\n","Epoch 11/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.2754 - accuracy: 0.9874 - val_loss: 0.2939 - val_accuracy: 0.9787\n","Epoch 12/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.2565 - accuracy: 0.9883 - val_loss: 0.2745 - val_accuracy: 0.9781\n","Epoch 13/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.2388 - accuracy: 0.9892 - val_loss: 0.2551 - val_accuracy: 0.9804\n","Epoch 14/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.2233 - accuracy: 0.9900 - val_loss: 0.2418 - val_accuracy: 0.9798\n","Epoch 15/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.2088 - accuracy: 0.9910 - val_loss: 0.2303 - val_accuracy: 0.9798\n","Epoch 16/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1958 - accuracy: 0.9920 - val_loss: 0.2192 - val_accuracy: 0.9805\n","Epoch 17/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1837 - accuracy: 0.9927 - val_loss: 0.2100 - val_accuracy: 0.9807\n","Epoch 18/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1727 - accuracy: 0.9932 - val_loss: 0.1985 - val_accuracy: 0.9802\n","Epoch 19/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1632 - accuracy: 0.9934 - val_loss: 0.1910 - val_accuracy: 0.9810\n","Epoch 20/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1540 - accuracy: 0.9941 - val_loss: 0.1829 - val_accuracy: 0.9814\n","Epoch 21/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1454 - accuracy: 0.9946 - val_loss: 0.1742 - val_accuracy: 0.9816\n","Epoch 22/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1377 - accuracy: 0.9951 - val_loss: 0.1782 - val_accuracy: 0.9780\n","Epoch 23/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1315 - accuracy: 0.9949 - val_loss: 0.1735 - val_accuracy: 0.9769\n","Epoch 24/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1253 - accuracy: 0.9954 - val_loss: 0.1589 - val_accuracy: 0.9803\n","Epoch 25/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1197 - accuracy: 0.9953 - val_loss: 0.1541 - val_accuracy: 0.9806\n","Epoch 26/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1140 - accuracy: 0.9959 - val_loss: 0.1467 - val_accuracy: 0.9818\n","Epoch 27/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1094 - accuracy: 0.9961 - val_loss: 0.1449 - val_accuracy: 0.9810\n","Epoch 28/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1044 - accuracy: 0.9965 - val_loss: 0.1387 - val_accuracy: 0.9816\n","Epoch 29/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1007 - accuracy: 0.9964 - val_loss: 0.1371 - val_accuracy: 0.9803\n","Epoch 30/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0968 - accuracy: 0.9966 - val_loss: 0.1311 - val_accuracy: 0.9828\n","Epoch 31/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0930 - accuracy: 0.9970 - val_loss: 0.1298 - val_accuracy: 0.9812\n","Epoch 32/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0905 - accuracy: 0.9967 - val_loss: 0.1264 - val_accuracy: 0.9823\n","Epoch 33/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0875 - accuracy: 0.9970 - val_loss: 0.1204 - val_accuracy: 0.9825\n","Epoch 34/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0845 - accuracy: 0.9971 - val_loss: 0.1202 - val_accuracy: 0.9826\n","Epoch 35/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0819 - accuracy: 0.9976 - val_loss: 0.1181 - val_accuracy: 0.9833\n","Epoch 36/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0798 - accuracy: 0.9972 - val_loss: 0.1155 - val_accuracy: 0.9831\n","Epoch 37/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0772 - accuracy: 0.9979 - val_loss: 0.1168 - val_accuracy: 0.9813\n","Epoch 38/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0754 - accuracy: 0.9975 - val_loss: 0.1117 - val_accuracy: 0.9823\n","Epoch 39/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0732 - accuracy: 0.9977 - val_loss: 0.1169 - val_accuracy: 0.9808\n","Epoch 40/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0718 - accuracy: 0.9980 - val_loss: 0.1129 - val_accuracy: 0.9820\n","Epoch 1/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.8842 - accuracy: 0.8881 - val_loss: 0.6853 - val_accuracy: 0.9353\n","Epoch 2/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.6400 - accuracy: 0.9444 - val_loss: 0.5841 - val_accuracy: 0.9551\n","Epoch 3/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.5571 - accuracy: 0.9584 - val_loss: 0.5240 - val_accuracy: 0.9617\n","Epoch 4/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.4974 - accuracy: 0.9676 - val_loss: 0.4996 - val_accuracy: 0.9595\n","Epoch 5/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.4506 - accuracy: 0.9724 - val_loss: 0.4371 - val_accuracy: 0.9709\n","Epoch 6/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.4109 - accuracy: 0.9767 - val_loss: 0.4110 - val_accuracy: 0.9715\n","Epoch 7/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.3769 - accuracy: 0.9793 - val_loss: 0.3750 - val_accuracy: 0.9751\n","Epoch 8/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.3461 - accuracy: 0.9828 - val_loss: 0.3534 - val_accuracy: 0.9742\n","Epoch 9/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.3196 - accuracy: 0.9847 - val_loss: 0.3322 - val_accuracy: 0.9761\n","Epoch 10/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.2955 - accuracy: 0.9865 - val_loss: 0.3048 - val_accuracy: 0.9792\n","Epoch 11/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.2741 - accuracy: 0.9878 - val_loss: 0.2864 - val_accuracy: 0.9787\n","Epoch 12/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.2549 - accuracy: 0.9890 - val_loss: 0.2725 - val_accuracy: 0.9788\n","Epoch 13/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.2375 - accuracy: 0.9897 - val_loss: 0.2646 - val_accuracy: 0.9775\n","Epoch 14/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.2218 - accuracy: 0.9909 - val_loss: 0.2444 - val_accuracy: 0.9791\n","Epoch 15/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.2076 - accuracy: 0.9914 - val_loss: 0.2288 - val_accuracy: 0.9803\n","Epoch 16/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1944 - accuracy: 0.9923 - val_loss: 0.2216 - val_accuracy: 0.9787\n","Epoch 17/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1830 - accuracy: 0.9926 - val_loss: 0.2070 - val_accuracy: 0.9820\n","Epoch 18/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1718 - accuracy: 0.9936 - val_loss: 0.1972 - val_accuracy: 0.9812\n","Epoch 19/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1618 - accuracy: 0.9943 - val_loss: 0.1906 - val_accuracy: 0.9808\n","Epoch 20/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1532 - accuracy: 0.9943 - val_loss: 0.1813 - val_accuracy: 0.9820\n","Epoch 21/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1449 - accuracy: 0.9952 - val_loss: 0.1799 - val_accuracy: 0.9795\n","Epoch 22/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1370 - accuracy: 0.9952 - val_loss: 0.1674 - val_accuracy: 0.9811\n","Epoch 23/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1304 - accuracy: 0.9955 - val_loss: 0.1591 - val_accuracy: 0.9829\n","Epoch 24/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1243 - accuracy: 0.9954 - val_loss: 0.1771 - val_accuracy: 0.9753\n","Epoch 25/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1186 - accuracy: 0.9959 - val_loss: 0.1493 - val_accuracy: 0.9829\n","Epoch 26/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1133 - accuracy: 0.9962 - val_loss: 0.1443 - val_accuracy: 0.9823\n","Epoch 27/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1083 - accuracy: 0.9966 - val_loss: 0.1448 - val_accuracy: 0.9811\n","Epoch 28/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1040 - accuracy: 0.9964 - val_loss: 0.1370 - val_accuracy: 0.9829\n","Epoch 29/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1002 - accuracy: 0.9966 - val_loss: 0.1369 - val_accuracy: 0.9797\n","Epoch 30/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1031 - accuracy: 0.9951 - val_loss: 0.1343 - val_accuracy: 0.9813\n","Epoch 31/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0947 - accuracy: 0.9963 - val_loss: 0.1286 - val_accuracy: 0.9821\n","Epoch 32/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0901 - accuracy: 0.9969 - val_loss: 0.1237 - val_accuracy: 0.9825\n","Epoch 33/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0867 - accuracy: 0.9973 - val_loss: 0.1277 - val_accuracy: 0.9803\n","Epoch 34/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0841 - accuracy: 0.9974 - val_loss: 0.1187 - val_accuracy: 0.9828\n","Epoch 35/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0817 - accuracy: 0.9976 - val_loss: 0.1182 - val_accuracy: 0.9820\n","Epoch 36/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0790 - accuracy: 0.9979 - val_loss: 0.1166 - val_accuracy: 0.9822\n","Epoch 37/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0771 - accuracy: 0.9978 - val_loss: 0.1201 - val_accuracy: 0.9802\n","Epoch 38/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0752 - accuracy: 0.9976 - val_loss: 0.1101 - val_accuracy: 0.9822\n","Epoch 39/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0733 - accuracy: 0.9977 - val_loss: 0.1087 - val_accuracy: 0.9831\n","Epoch 40/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0715 - accuracy: 0.9982 - val_loss: 0.1080 - val_accuracy: 0.9826\n","Epoch 1/40\n","469/469 [==============================] - 3s 6ms/step - loss: 1.1148 - accuracy: 0.8867 - val_loss: 0.8880 - val_accuracy: 0.9360\n","Epoch 2/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.8239 - accuracy: 0.9424 - val_loss: 0.7609 - val_accuracy: 0.9480\n","Epoch 3/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.7033 - accuracy: 0.9574 - val_loss: 0.6523 - val_accuracy: 0.9594\n","Epoch 4/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.6128 - accuracy: 0.9664 - val_loss: 0.5837 - val_accuracy: 0.9641\n","Epoch 5/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.5391 - accuracy: 0.9716 - val_loss: 0.5133 - val_accuracy: 0.9690\n","Epoch 6/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.4787 - accuracy: 0.9751 - val_loss: 0.4623 - val_accuracy: 0.9717\n","Epoch 7/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.4266 - accuracy: 0.9782 - val_loss: 0.4187 - val_accuracy: 0.9721\n","Epoch 8/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.3827 - accuracy: 0.9798 - val_loss: 0.3739 - val_accuracy: 0.9755\n","Epoch 9/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.3441 - accuracy: 0.9827 - val_loss: 0.3469 - val_accuracy: 0.9740\n","Epoch 10/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.3108 - accuracy: 0.9841 - val_loss: 0.3108 - val_accuracy: 0.9769\n","Epoch 11/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.2816 - accuracy: 0.9849 - val_loss: 0.2854 - val_accuracy: 0.9781\n","Epoch 12/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.2570 - accuracy: 0.9865 - val_loss: 0.2726 - val_accuracy: 0.9756\n","Epoch 13/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.2354 - accuracy: 0.9874 - val_loss: 0.2477 - val_accuracy: 0.9775\n","Epoch 14/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.2166 - accuracy: 0.9878 - val_loss: 0.2320 - val_accuracy: 0.9778\n","Epoch 15/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.2001 - accuracy: 0.9885 - val_loss: 0.2167 - val_accuracy: 0.9782\n","Epoch 16/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1858 - accuracy: 0.9888 - val_loss: 0.2022 - val_accuracy: 0.9803\n","Epoch 17/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1725 - accuracy: 0.9900 - val_loss: 0.1934 - val_accuracy: 0.9793\n","Epoch 18/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1619 - accuracy: 0.9902 - val_loss: 0.1845 - val_accuracy: 0.9791\n","Epoch 19/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1519 - accuracy: 0.9908 - val_loss: 0.1712 - val_accuracy: 0.9809\n","Epoch 20/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1429 - accuracy: 0.9913 - val_loss: 0.1673 - val_accuracy: 0.9786\n","Epoch 21/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1361 - accuracy: 0.9913 - val_loss: 0.1681 - val_accuracy: 0.9779\n","Epoch 22/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1288 - accuracy: 0.9921 - val_loss: 0.1521 - val_accuracy: 0.9809\n","Epoch 23/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1233 - accuracy: 0.9920 - val_loss: 0.1522 - val_accuracy: 0.9785\n","Epoch 24/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1171 - accuracy: 0.9931 - val_loss: 0.1501 - val_accuracy: 0.9777\n","Epoch 25/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1125 - accuracy: 0.9934 - val_loss: 0.1410 - val_accuracy: 0.9803\n","Epoch 26/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1083 - accuracy: 0.9933 - val_loss: 0.1392 - val_accuracy: 0.9799\n","Epoch 27/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1055 - accuracy: 0.9929 - val_loss: 0.1315 - val_accuracy: 0.9817\n","Epoch 28/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1013 - accuracy: 0.9936 - val_loss: 0.1359 - val_accuracy: 0.9788\n","Epoch 29/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0984 - accuracy: 0.9937 - val_loss: 0.1239 - val_accuracy: 0.9818\n","Epoch 30/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0955 - accuracy: 0.9940 - val_loss: 0.1240 - val_accuracy: 0.9816\n","Epoch 31/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0933 - accuracy: 0.9944 - val_loss: 0.1270 - val_accuracy: 0.9795\n","Epoch 32/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0910 - accuracy: 0.9946 - val_loss: 0.1199 - val_accuracy: 0.9816\n","Epoch 33/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0894 - accuracy: 0.9944 - val_loss: 0.1426 - val_accuracy: 0.9750\n","Epoch 34/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0877 - accuracy: 0.9947 - val_loss: 0.1203 - val_accuracy: 0.9797\n","Epoch 35/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0855 - accuracy: 0.9947 - val_loss: 0.1173 - val_accuracy: 0.9814\n","Epoch 36/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0843 - accuracy: 0.9950 - val_loss: 0.1180 - val_accuracy: 0.9805\n","Epoch 37/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0831 - accuracy: 0.9949 - val_loss: 0.1160 - val_accuracy: 0.9811\n","Epoch 38/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0819 - accuracy: 0.9949 - val_loss: 0.1105 - val_accuracy: 0.9817\n","Epoch 39/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0804 - accuracy: 0.9953 - val_loss: 0.1114 - val_accuracy: 0.9812\n","Epoch 40/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0795 - accuracy: 0.9953 - val_loss: 0.1085 - val_accuracy: 0.9821\n","Epoch 1/40\n","469/469 [==============================] - 4s 6ms/step - loss: 1.1151 - accuracy: 0.8876 - val_loss: 0.9030 - val_accuracy: 0.9301\n","Epoch 2/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.8238 - accuracy: 0.9434 - val_loss: 0.7537 - val_accuracy: 0.9513\n","Epoch 3/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.7039 - accuracy: 0.9575 - val_loss: 0.6595 - val_accuracy: 0.9600\n","Epoch 4/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.6126 - accuracy: 0.9664 - val_loss: 0.5826 - val_accuracy: 0.9633\n","Epoch 5/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.5393 - accuracy: 0.9718 - val_loss: 0.5141 - val_accuracy: 0.9691\n","Epoch 6/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.4784 - accuracy: 0.9754 - val_loss: 0.4636 - val_accuracy: 0.9709\n","Epoch 7/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.4267 - accuracy: 0.9779 - val_loss: 0.4206 - val_accuracy: 0.9718\n","Epoch 8/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.3819 - accuracy: 0.9803 - val_loss: 0.3773 - val_accuracy: 0.9737\n","Epoch 9/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.3433 - accuracy: 0.9826 - val_loss: 0.3413 - val_accuracy: 0.9758\n","Epoch 10/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.3100 - accuracy: 0.9840 - val_loss: 0.3135 - val_accuracy: 0.9763\n","Epoch 11/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.2814 - accuracy: 0.9848 - val_loss: 0.2868 - val_accuracy: 0.9771\n","Epoch 12/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.2566 - accuracy: 0.9863 - val_loss: 0.2697 - val_accuracy: 0.9769\n","Epoch 13/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.2351 - accuracy: 0.9872 - val_loss: 0.2516 - val_accuracy: 0.9772\n","Epoch 14/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.2159 - accuracy: 0.9882 - val_loss: 0.2363 - val_accuracy: 0.9771\n","Epoch 15/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1998 - accuracy: 0.9891 - val_loss: 0.2190 - val_accuracy: 0.9777\n","Epoch 16/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1847 - accuracy: 0.9897 - val_loss: 0.2042 - val_accuracy: 0.9789\n","Epoch 17/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1724 - accuracy: 0.9898 - val_loss: 0.1944 - val_accuracy: 0.9777\n","Epoch 18/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1605 - accuracy: 0.9912 - val_loss: 0.1804 - val_accuracy: 0.9800\n","Epoch 19/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1512 - accuracy: 0.9908 - val_loss: 0.1756 - val_accuracy: 0.9800\n","Epoch 20/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1424 - accuracy: 0.9915 - val_loss: 0.1690 - val_accuracy: 0.9795\n","Epoch 21/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1346 - accuracy: 0.9918 - val_loss: 0.1631 - val_accuracy: 0.9780\n","Epoch 22/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1292 - accuracy: 0.9916 - val_loss: 0.1549 - val_accuracy: 0.9806\n","Epoch 23/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1220 - accuracy: 0.9925 - val_loss: 0.1536 - val_accuracy: 0.9797\n","Epoch 24/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1166 - accuracy: 0.9930 - val_loss: 0.1409 - val_accuracy: 0.9819\n","Epoch 25/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1125 - accuracy: 0.9930 - val_loss: 0.1373 - val_accuracy: 0.9811\n","Epoch 26/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1081 - accuracy: 0.9931 - val_loss: 0.1369 - val_accuracy: 0.9809\n","Epoch 27/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1042 - accuracy: 0.9939 - val_loss: 0.1350 - val_accuracy: 0.9793\n","Epoch 28/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1010 - accuracy: 0.9938 - val_loss: 0.1266 - val_accuracy: 0.9830\n","Epoch 29/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0977 - accuracy: 0.9940 - val_loss: 0.1329 - val_accuracy: 0.9791\n","Epoch 30/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0954 - accuracy: 0.9941 - val_loss: 0.1298 - val_accuracy: 0.9815\n","Epoch 31/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0929 - accuracy: 0.9941 - val_loss: 0.1233 - val_accuracy: 0.9809\n","Epoch 32/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0906 - accuracy: 0.9949 - val_loss: 0.1348 - val_accuracy: 0.9766\n","Epoch 33/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0879 - accuracy: 0.9949 - val_loss: 0.1198 - val_accuracy: 0.9823\n","Epoch 34/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0866 - accuracy: 0.9950 - val_loss: 0.1178 - val_accuracy: 0.9815\n","Epoch 35/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0852 - accuracy: 0.9951 - val_loss: 0.1141 - val_accuracy: 0.9831\n","Epoch 36/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0840 - accuracy: 0.9948 - val_loss: 0.1129 - val_accuracy: 0.9833\n","Epoch 37/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0824 - accuracy: 0.9953 - val_loss: 0.1133 - val_accuracy: 0.9826\n","Epoch 38/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0818 - accuracy: 0.9950 - val_loss: 0.1152 - val_accuracy: 0.9819\n","Epoch 39/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0796 - accuracy: 0.9954 - val_loss: 0.1149 - val_accuracy: 0.9810\n","Epoch 40/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0791 - accuracy: 0.9955 - val_loss: 0.1158 - val_accuracy: 0.9804\n","Epoch 1/40\n","469/469 [==============================] - 3s 6ms/step - loss: 1.1098 - accuracy: 0.8872 - val_loss: 0.8859 - val_accuracy: 0.9366\n","Epoch 2/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.8226 - accuracy: 0.9432 - val_loss: 0.7516 - val_accuracy: 0.9524\n","Epoch 3/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.7026 - accuracy: 0.9578 - val_loss: 0.6751 - val_accuracy: 0.9544\n","Epoch 4/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.6112 - accuracy: 0.9660 - val_loss: 0.5754 - val_accuracy: 0.9668\n","Epoch 5/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.5381 - accuracy: 0.9714 - val_loss: 0.5119 - val_accuracy: 0.9709\n","Epoch 6/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.4769 - accuracy: 0.9761 - val_loss: 0.4637 - val_accuracy: 0.9711\n","Epoch 7/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.4253 - accuracy: 0.9779 - val_loss: 0.4135 - val_accuracy: 0.9738\n","Epoch 8/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.3799 - accuracy: 0.9813 - val_loss: 0.3784 - val_accuracy: 0.9744\n","Epoch 9/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.3418 - accuracy: 0.9826 - val_loss: 0.3425 - val_accuracy: 0.9774\n","Epoch 10/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.3090 - accuracy: 0.9841 - val_loss: 0.3158 - val_accuracy: 0.9762\n","Epoch 11/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.2803 - accuracy: 0.9851 - val_loss: 0.2867 - val_accuracy: 0.9794\n","Epoch 12/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.2556 - accuracy: 0.9865 - val_loss: 0.2675 - val_accuracy: 0.9771\n","Epoch 13/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.2342 - accuracy: 0.9875 - val_loss: 0.2500 - val_accuracy: 0.9768\n","Epoch 14/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.2152 - accuracy: 0.9880 - val_loss: 0.2359 - val_accuracy: 0.9780\n","Epoch 15/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1993 - accuracy: 0.9885 - val_loss: 0.2213 - val_accuracy: 0.9780\n","Epoch 16/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1837 - accuracy: 0.9898 - val_loss: 0.2036 - val_accuracy: 0.9781\n","Epoch 17/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1712 - accuracy: 0.9906 - val_loss: 0.1892 - val_accuracy: 0.9803\n","Epoch 18/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1595 - accuracy: 0.9911 - val_loss: 0.1942 - val_accuracy: 0.9766\n","Epoch 19/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1502 - accuracy: 0.9912 - val_loss: 0.1735 - val_accuracy: 0.9799\n","Epoch 20/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1419 - accuracy: 0.9916 - val_loss: 0.1640 - val_accuracy: 0.9803\n","Epoch 21/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1345 - accuracy: 0.9923 - val_loss: 0.1565 - val_accuracy: 0.9817\n","Epoch 22/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1271 - accuracy: 0.9927 - val_loss: 0.1596 - val_accuracy: 0.9785\n","Epoch 23/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1214 - accuracy: 0.9927 - val_loss: 0.1480 - val_accuracy: 0.9811\n","Epoch 24/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1163 - accuracy: 0.9930 - val_loss: 0.1464 - val_accuracy: 0.9805\n","Epoch 25/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1117 - accuracy: 0.9931 - val_loss: 0.1443 - val_accuracy: 0.9789\n","Epoch 26/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1073 - accuracy: 0.9939 - val_loss: 0.1345 - val_accuracy: 0.9814\n","Epoch 27/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1035 - accuracy: 0.9940 - val_loss: 0.1319 - val_accuracy: 0.9818\n","Epoch 28/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1007 - accuracy: 0.9942 - val_loss: 0.1371 - val_accuracy: 0.9780\n","Epoch 29/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0976 - accuracy: 0.9940 - val_loss: 0.1294 - val_accuracy: 0.9816\n","Epoch 30/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0949 - accuracy: 0.9942 - val_loss: 0.1280 - val_accuracy: 0.9804\n","Epoch 31/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0918 - accuracy: 0.9948 - val_loss: 0.1241 - val_accuracy: 0.9823\n","Epoch 32/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0902 - accuracy: 0.9946 - val_loss: 0.1310 - val_accuracy: 0.9778\n","Epoch 33/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0881 - accuracy: 0.9948 - val_loss: 0.1243 - val_accuracy: 0.9810\n","Epoch 34/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0863 - accuracy: 0.9951 - val_loss: 0.1154 - val_accuracy: 0.9828\n","Epoch 35/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0845 - accuracy: 0.9952 - val_loss: 0.1166 - val_accuracy: 0.9823\n","Epoch 36/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0840 - accuracy: 0.9949 - val_loss: 0.1133 - val_accuracy: 0.9827\n","Epoch 37/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0816 - accuracy: 0.9958 - val_loss: 0.1197 - val_accuracy: 0.9786\n","Epoch 38/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0808 - accuracy: 0.9955 - val_loss: 0.1116 - val_accuracy: 0.9823\n","Epoch 39/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0796 - accuracy: 0.9955 - val_loss: 0.1133 - val_accuracy: 0.9820\n","Epoch 40/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0785 - accuracy: 0.9958 - val_loss: 0.1097 - val_accuracy: 0.9818\n","Epoch 1/40\n","469/469 [==============================] - 4s 6ms/step - loss: 1.3296 - accuracy: 0.8870 - val_loss: 1.0725 - val_accuracy: 0.9358\n","Epoch 2/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.9825 - accuracy: 0.9416 - val_loss: 0.8844 - val_accuracy: 0.9532\n","Epoch 3/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.8150 - accuracy: 0.9562 - val_loss: 0.7576 - val_accuracy: 0.9559\n","Epoch 4/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.6885 - accuracy: 0.9643 - val_loss: 0.6431 - val_accuracy: 0.9644\n","Epoch 5/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.5878 - accuracy: 0.9701 - val_loss: 0.5473 - val_accuracy: 0.9690\n","Epoch 6/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.5053 - accuracy: 0.9740 - val_loss: 0.4821 - val_accuracy: 0.9712\n","Epoch 7/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.4387 - accuracy: 0.9768 - val_loss: 0.4196 - val_accuracy: 0.9725\n","Epoch 8/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.3836 - accuracy: 0.9793 - val_loss: 0.3707 - val_accuracy: 0.9743\n","Epoch 9/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.3372 - accuracy: 0.9810 - val_loss: 0.3343 - val_accuracy: 0.9746\n","Epoch 10/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.2995 - accuracy: 0.9822 - val_loss: 0.2983 - val_accuracy: 0.9757\n","Epoch 11/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.2673 - accuracy: 0.9834 - val_loss: 0.2684 - val_accuracy: 0.9768\n","Epoch 12/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.2409 - accuracy: 0.9850 - val_loss: 0.2513 - val_accuracy: 0.9749\n","Epoch 13/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.2186 - accuracy: 0.9851 - val_loss: 0.2288 - val_accuracy: 0.9776\n","Epoch 14/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.2006 - accuracy: 0.9861 - val_loss: 0.2124 - val_accuracy: 0.9792\n","Epoch 15/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1841 - accuracy: 0.9874 - val_loss: 0.1992 - val_accuracy: 0.9773\n","Epoch 16/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1712 - accuracy: 0.9871 - val_loss: 0.1841 - val_accuracy: 0.9787\n","Epoch 17/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1596 - accuracy: 0.9884 - val_loss: 0.1969 - val_accuracy: 0.9723\n","Epoch 18/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1505 - accuracy: 0.9884 - val_loss: 0.1701 - val_accuracy: 0.9792\n","Epoch 19/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1430 - accuracy: 0.9884 - val_loss: 0.1645 - val_accuracy: 0.9795\n","Epoch 20/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1350 - accuracy: 0.9894 - val_loss: 0.1558 - val_accuracy: 0.9803\n","Epoch 21/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1296 - accuracy: 0.9896 - val_loss: 0.1479 - val_accuracy: 0.9806\n","Epoch 22/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1244 - accuracy: 0.9903 - val_loss: 0.1460 - val_accuracy: 0.9812\n","Epoch 23/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1206 - accuracy: 0.9901 - val_loss: 0.1478 - val_accuracy: 0.9786\n","Epoch 24/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1157 - accuracy: 0.9907 - val_loss: 0.1397 - val_accuracy: 0.9806\n","Epoch 25/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1122 - accuracy: 0.9912 - val_loss: 0.1347 - val_accuracy: 0.9814\n","Epoch 26/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1101 - accuracy: 0.9912 - val_loss: 0.1368 - val_accuracy: 0.9799\n","Epoch 27/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1071 - accuracy: 0.9912 - val_loss: 0.1382 - val_accuracy: 0.9793\n","Epoch 28/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1050 - accuracy: 0.9915 - val_loss: 0.1269 - val_accuracy: 0.9814\n","Epoch 29/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1033 - accuracy: 0.9916 - val_loss: 0.1358 - val_accuracy: 0.9783\n","Epoch 30/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1012 - accuracy: 0.9924 - val_loss: 0.1264 - val_accuracy: 0.9818\n","Epoch 31/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0996 - accuracy: 0.9925 - val_loss: 0.1301 - val_accuracy: 0.9786\n","Epoch 32/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0981 - accuracy: 0.9920 - val_loss: 0.1262 - val_accuracy: 0.9813\n","Epoch 33/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0965 - accuracy: 0.9925 - val_loss: 0.1270 - val_accuracy: 0.9800\n","Epoch 34/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0954 - accuracy: 0.9926 - val_loss: 0.1436 - val_accuracy: 0.9726\n","Epoch 35/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0944 - accuracy: 0.9928 - val_loss: 0.1242 - val_accuracy: 0.9804\n","Epoch 36/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0935 - accuracy: 0.9926 - val_loss: 0.1277 - val_accuracy: 0.9800\n","Epoch 37/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0921 - accuracy: 0.9933 - val_loss: 0.1191 - val_accuracy: 0.9820\n","Epoch 38/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0912 - accuracy: 0.9930 - val_loss: 0.1186 - val_accuracy: 0.9816\n","Epoch 39/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0906 - accuracy: 0.9933 - val_loss: 0.1245 - val_accuracy: 0.9795\n","Epoch 40/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0905 - accuracy: 0.9933 - val_loss: 0.1261 - val_accuracy: 0.9797\n","Epoch 1/40\n","469/469 [==============================] - 4s 7ms/step - loss: 1.3262 - accuracy: 0.8881 - val_loss: 1.0749 - val_accuracy: 0.9358\n","Epoch 2/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.9795 - accuracy: 0.9425 - val_loss: 0.8763 - val_accuracy: 0.9529\n","Epoch 3/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.8129 - accuracy: 0.9576 - val_loss: 0.7420 - val_accuracy: 0.9622\n","Epoch 4/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.6869 - accuracy: 0.9653 - val_loss: 0.6353 - val_accuracy: 0.9656\n","Epoch 5/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.5862 - accuracy: 0.9705 - val_loss: 0.5519 - val_accuracy: 0.9672\n","Epoch 6/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.5047 - accuracy: 0.9742 - val_loss: 0.4866 - val_accuracy: 0.9692\n","Epoch 7/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.4378 - accuracy: 0.9770 - val_loss: 0.4245 - val_accuracy: 0.9711\n","Epoch 8/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.3826 - accuracy: 0.9794 - val_loss: 0.3757 - val_accuracy: 0.9735\n","Epoch 9/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.3373 - accuracy: 0.9812 - val_loss: 0.3284 - val_accuracy: 0.9762\n","Epoch 10/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.2992 - accuracy: 0.9825 - val_loss: 0.2984 - val_accuracy: 0.9758\n","Epoch 11/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.2668 - accuracy: 0.9835 - val_loss: 0.2708 - val_accuracy: 0.9766\n","Epoch 12/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.2409 - accuracy: 0.9846 - val_loss: 0.2514 - val_accuracy: 0.9766\n","Epoch 13/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.2185 - accuracy: 0.9858 - val_loss: 0.2313 - val_accuracy: 0.9755\n","Epoch 14/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.2008 - accuracy: 0.9862 - val_loss: 0.2084 - val_accuracy: 0.9795\n","Epoch 15/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1852 - accuracy: 0.9865 - val_loss: 0.1943 - val_accuracy: 0.9802\n","Epoch 16/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1711 - accuracy: 0.9879 - val_loss: 0.1907 - val_accuracy: 0.9783\n","Epoch 17/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1606 - accuracy: 0.9876 - val_loss: 0.1750 - val_accuracy: 0.9805\n","Epoch 18/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1506 - accuracy: 0.9883 - val_loss: 0.1710 - val_accuracy: 0.9791\n","Epoch 19/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1428 - accuracy: 0.9891 - val_loss: 0.1723 - val_accuracy: 0.9756\n","Epoch 20/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1361 - accuracy: 0.9890 - val_loss: 0.1576 - val_accuracy: 0.9798\n","Epoch 21/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1301 - accuracy: 0.9897 - val_loss: 0.1547 - val_accuracy: 0.9789\n","Epoch 22/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1248 - accuracy: 0.9903 - val_loss: 0.1465 - val_accuracy: 0.9798\n","Epoch 23/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1208 - accuracy: 0.9900 - val_loss: 0.1466 - val_accuracy: 0.9800\n","Epoch 24/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1163 - accuracy: 0.9905 - val_loss: 0.1776 - val_accuracy: 0.9670\n","Epoch 25/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1130 - accuracy: 0.9911 - val_loss: 0.1343 - val_accuracy: 0.9817\n","Epoch 26/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1107 - accuracy: 0.9912 - val_loss: 0.1313 - val_accuracy: 0.9821\n","Epoch 27/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1080 - accuracy: 0.9912 - val_loss: 0.1309 - val_accuracy: 0.9819\n","Epoch 28/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1055 - accuracy: 0.9917 - val_loss: 0.1546 - val_accuracy: 0.9713\n","Epoch 29/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1034 - accuracy: 0.9922 - val_loss: 0.1304 - val_accuracy: 0.9789\n","Epoch 30/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1013 - accuracy: 0.9921 - val_loss: 0.1253 - val_accuracy: 0.9817\n","Epoch 31/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1008 - accuracy: 0.9920 - val_loss: 0.1289 - val_accuracy: 0.9811\n","Epoch 32/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0986 - accuracy: 0.9923 - val_loss: 0.1237 - val_accuracy: 0.9817\n","Epoch 33/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0968 - accuracy: 0.9926 - val_loss: 0.1223 - val_accuracy: 0.9820\n","Epoch 34/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0948 - accuracy: 0.9932 - val_loss: 0.1245 - val_accuracy: 0.9804\n","Epoch 35/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0946 - accuracy: 0.9929 - val_loss: 0.1213 - val_accuracy: 0.9803\n","Epoch 36/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0939 - accuracy: 0.9928 - val_loss: 0.1249 - val_accuracy: 0.9810\n","Epoch 37/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0930 - accuracy: 0.9927 - val_loss: 0.1187 - val_accuracy: 0.9816\n","Epoch 38/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0908 - accuracy: 0.9939 - val_loss: 0.1186 - val_accuracy: 0.9814\n","Epoch 39/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0907 - accuracy: 0.9935 - val_loss: 0.1166 - val_accuracy: 0.9830\n","Epoch 40/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0899 - accuracy: 0.9934 - val_loss: 0.1213 - val_accuracy: 0.9806\n","Epoch 1/40\n","469/469 [==============================] - 4s 7ms/step - loss: 1.3237 - accuracy: 0.8891 - val_loss: 1.0792 - val_accuracy: 0.9321\n","Epoch 2/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.9794 - accuracy: 0.9435 - val_loss: 0.8849 - val_accuracy: 0.9538\n","Epoch 3/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.8119 - accuracy: 0.9574 - val_loss: 0.7457 - val_accuracy: 0.9607\n","Epoch 4/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.6859 - accuracy: 0.9654 - val_loss: 0.6483 - val_accuracy: 0.9633\n","Epoch 5/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.5859 - accuracy: 0.9709 - val_loss: 0.5505 - val_accuracy: 0.9711\n","Epoch 6/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.5041 - accuracy: 0.9747 - val_loss: 0.4930 - val_accuracy: 0.9680\n","Epoch 7/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.4371 - accuracy: 0.9772 - val_loss: 0.4195 - val_accuracy: 0.9737\n","Epoch 8/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.3824 - accuracy: 0.9793 - val_loss: 0.3791 - val_accuracy: 0.9728\n","Epoch 9/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.3366 - accuracy: 0.9812 - val_loss: 0.3399 - val_accuracy: 0.9727\n","Epoch 10/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.2988 - accuracy: 0.9819 - val_loss: 0.2948 - val_accuracy: 0.9771\n","Epoch 11/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.2671 - accuracy: 0.9842 - val_loss: 0.2677 - val_accuracy: 0.9785\n","Epoch 12/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.2408 - accuracy: 0.9847 - val_loss: 0.2476 - val_accuracy: 0.9776\n","Epoch 13/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.2184 - accuracy: 0.9857 - val_loss: 0.2295 - val_accuracy: 0.9775\n","Epoch 14/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.2005 - accuracy: 0.9866 - val_loss: 0.2150 - val_accuracy: 0.9767\n","Epoch 15/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1843 - accuracy: 0.9871 - val_loss: 0.1974 - val_accuracy: 0.9780\n","Epoch 16/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1714 - accuracy: 0.9872 - val_loss: 0.1891 - val_accuracy: 0.9785\n","Epoch 17/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1601 - accuracy: 0.9885 - val_loss: 0.1743 - val_accuracy: 0.9808\n","Epoch 18/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1504 - accuracy: 0.9882 - val_loss: 0.1668 - val_accuracy: 0.9802\n","Epoch 19/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1420 - accuracy: 0.9892 - val_loss: 0.1694 - val_accuracy: 0.9776\n","Epoch 20/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1360 - accuracy: 0.9892 - val_loss: 0.1624 - val_accuracy: 0.9769\n","Epoch 21/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1300 - accuracy: 0.9895 - val_loss: 0.1540 - val_accuracy: 0.9789\n","Epoch 22/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1244 - accuracy: 0.9905 - val_loss: 0.1475 - val_accuracy: 0.9794\n","Epoch 23/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1202 - accuracy: 0.9903 - val_loss: 0.1480 - val_accuracy: 0.9789\n","Epoch 24/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1167 - accuracy: 0.9905 - val_loss: 0.1414 - val_accuracy: 0.9798\n","Epoch 25/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1137 - accuracy: 0.9909 - val_loss: 0.1353 - val_accuracy: 0.9814\n","Epoch 26/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1097 - accuracy: 0.9917 - val_loss: 0.1343 - val_accuracy: 0.9808\n","Epoch 27/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1073 - accuracy: 0.9916 - val_loss: 0.1359 - val_accuracy: 0.9788\n","Epoch 28/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1051 - accuracy: 0.9915 - val_loss: 0.1370 - val_accuracy: 0.9791\n","Epoch 29/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1029 - accuracy: 0.9918 - val_loss: 0.1287 - val_accuracy: 0.9799\n","Epoch 30/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.1009 - accuracy: 0.9921 - val_loss: 0.1260 - val_accuracy: 0.9807\n","Epoch 31/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0993 - accuracy: 0.9925 - val_loss: 0.1240 - val_accuracy: 0.9821\n","Epoch 32/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0978 - accuracy: 0.9924 - val_loss: 0.1266 - val_accuracy: 0.9807\n","Epoch 33/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0969 - accuracy: 0.9921 - val_loss: 0.1210 - val_accuracy: 0.9828\n","Epoch 34/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0961 - accuracy: 0.9926 - val_loss: 0.1282 - val_accuracy: 0.9788\n","Epoch 35/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0951 - accuracy: 0.9923 - val_loss: 0.1217 - val_accuracy: 0.9807\n","Epoch 36/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0935 - accuracy: 0.9930 - val_loss: 0.1242 - val_accuracy: 0.9800\n","Epoch 37/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0922 - accuracy: 0.9932 - val_loss: 0.1217 - val_accuracy: 0.9806\n","Epoch 38/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0912 - accuracy: 0.9934 - val_loss: 0.1345 - val_accuracy: 0.9758\n","Epoch 39/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0908 - accuracy: 0.9933 - val_loss: 0.1201 - val_accuracy: 0.9819\n","Epoch 40/40\n","469/469 [==============================] - 3s 6ms/step - loss: 0.0898 - accuracy: 0.9931 - val_loss: 0.1192 - val_accuracy: 0.9808\n"]}]},{"cell_type":"code","source":["# Plot inspired by: https://scikit-learn.org/stable/auto_examples/model_selection/plot_validation_curve.html#sphx-glr-auto-examples-model-selection-plot-validation-curve-py\n","param_range = np.logspace(-6, -3, 5)\n","mean = np.mean(val_accuracy, axis=1)\n","std = np.std(val_accuracy, axis=1)\n","\n","plt.semilogx(\n","    param_range, mean, label=\"Cross-validation score\", color=\"navy\", lw=2\n",")\n","plt.fill_between(\n","    param_range,\n","    mean - std,\n","    mean + std,\n","    alpha=0.2,\n","    color=\"navy\",\n","    lw=2,\n",")\n","plt.title('Integer number prediction')\n","plt.ylabel('Accuracy')\n","plt.xlabel('Weight decay')\n","plt.legend(['Mean validation score'], loc='upper right')\n","plt.show()\n","\n","print(\"Maximum validation accuracy achieved:\", max(mean))"],"metadata":{"id":"qF8P3KriUMVC","colab":{"base_uri":"https://localhost:8080/","height":316},"executionInfo":{"status":"ok","timestamp":1639648795970,"user_tz":-60,"elapsed":1157,"user":{"displayName":"Carl Hjalmarsson","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjPhXRyxfUmz6QECuK-KbhNTYdiIjr8547K5LaklQ=s64","userId":"03986481713830842027"}},"outputId":"b1245d87-8adc-45c0-cc15-66ecf0d7db8c"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}},{"output_type":"stream","name":"stdout","text":["Maximum validation accuracy achieved: 0.9821999867757162\n"]}]},{"cell_type":"markdown","source":["#### Analysis of results\n","Our validation accuracy is approximately 0.0025 lower than Geoff Hinton's results, which is very close; the relative error between the results is 0.25%. It's hard to argue which factors makes up the difference as it is so small, however one factor of note that differs between our and Hinton's model is that Hinton uses 50 epochs as well as conjugate gradient descent. Another factor is the choice of learning rate, which we were unable to find when reviewing Hinton's publicly available material.\n"],"metadata":{"id":"oq4U8MAANocf"}},{"cell_type":"markdown","source":["### Question 3\n","### a)"],"metadata":{"id":"PYK02Ie0PVl1"}},{"cell_type":"code","source":["## Source code found at https://medium.com/@mgazar/lenet-5-in-9-lines-of-code-using-keras-ac99294c8086\n","model = Sequential()\n","epochs = 50\n","## Padding for training and test data\n","\n","x_train_pad = tf.pad(tf.convert_to_tensor(x_train), tf.constant([[0,0], [2,2], [2, 2], [0, 0]]), mode=\"CONSTANT\")\n","x_test_pad = tf.pad(tf.convert_to_tensor(x_test), tf.constant([[0,0], [2,2], [2, 2], [0, 0]]), mode=\"CONSTANT\")\n","\n","model.add(Conv2D(filters=6, kernel_size=(3, 3), activation='relu', input_shape=(32,32,1), padding = \"same\"))\n","model.add(AveragePooling2D())\n","\n","model.add(Conv2D(filters=16, kernel_size=(3, 3), activation='relu'))\n","model.add(AveragePooling2D())\n","\n","model.add(Flatten())\n","\n","model.add(Dense(units=120, activation='relu'))\n","\n","model.add(Dense(units=84, activation='relu'))\n","\n","model.add(Dense(num_classes, activation = 'softmax'))\n","\n","model.compile(loss=tf.keras.losses.categorical_crossentropy,\n","               optimizer=tf.keras.optimizers.SGD(lr = 0.1),\n","        metrics=['accuracy'])\n","\n","fit_info = model.fit(x_train_pad, y_train,\n","           batch_size=batch_size,\n","           epochs=epochs,\n","           verbose=1,\n","           validation_data=(x_test_pad, y_test))\n","score = model.evaluate(x_test_pad, y_test, verbose=0)\n","print('Test loss: {}, Test accuracy {}'.format(score[0], score[1]))\n"],"metadata":{"id":"lEgW7-U_OqrV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1639734410326,"user_tz":-60,"elapsed":195594,"user":{"displayName":"Noah Lanai","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3gMuaTxwLJbby0Vp5tDORsb1KtaWfwA3UALybUw=s64","userId":"07227027853094350298"}},"outputId":"59824847-3804-4c9e-a221-281322045055"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super(SGD, self).__init__(name, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","469/469 [==============================] - 7s 13ms/step - loss: 0.4986 - accuracy: 0.8515 - val_loss: 0.1474 - val_accuracy: 0.9556\n","Epoch 2/50\n","469/469 [==============================] - 6s 12ms/step - loss: 0.1307 - accuracy: 0.9603 - val_loss: 0.1272 - val_accuracy: 0.9583\n","Epoch 3/50\n","469/469 [==============================] - 5s 10ms/step - loss: 0.0919 - accuracy: 0.9718 - val_loss: 0.0853 - val_accuracy: 0.9713\n","Epoch 4/50\n","469/469 [==============================] - 4s 7ms/step - loss: 0.0729 - accuracy: 0.9780 - val_loss: 0.0716 - val_accuracy: 0.9779\n","Epoch 5/50\n","469/469 [==============================] - 4s 7ms/step - loss: 0.0625 - accuracy: 0.9808 - val_loss: 0.0595 - val_accuracy: 0.9805\n","Epoch 6/50\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0532 - accuracy: 0.9833 - val_loss: 0.0590 - val_accuracy: 0.9817\n","Epoch 7/50\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0471 - accuracy: 0.9855 - val_loss: 0.0562 - val_accuracy: 0.9816\n","Epoch 8/50\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0418 - accuracy: 0.9865 - val_loss: 0.0489 - val_accuracy: 0.9839\n","Epoch 9/50\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0369 - accuracy: 0.9885 - val_loss: 0.0450 - val_accuracy: 0.9847\n","Epoch 10/50\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0328 - accuracy: 0.9898 - val_loss: 0.0521 - val_accuracy: 0.9835\n","Epoch 11/50\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0303 - accuracy: 0.9903 - val_loss: 0.0466 - val_accuracy: 0.9853\n","Epoch 12/50\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0268 - accuracy: 0.9914 - val_loss: 0.0501 - val_accuracy: 0.9839\n","Epoch 13/50\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0252 - accuracy: 0.9919 - val_loss: 0.0579 - val_accuracy: 0.9814\n","Epoch 14/50\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0220 - accuracy: 0.9931 - val_loss: 0.0416 - val_accuracy: 0.9867\n","Epoch 15/50\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0200 - accuracy: 0.9937 - val_loss: 0.0462 - val_accuracy: 0.9857\n","Epoch 16/50\n","469/469 [==============================] - 4s 7ms/step - loss: 0.0187 - accuracy: 0.9940 - val_loss: 0.0439 - val_accuracy: 0.9859\n","Epoch 17/50\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0158 - accuracy: 0.9951 - val_loss: 0.0474 - val_accuracy: 0.9851\n","Epoch 18/50\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0152 - accuracy: 0.9952 - val_loss: 0.0401 - val_accuracy: 0.9879\n","Epoch 19/50\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0151 - accuracy: 0.9950 - val_loss: 0.0540 - val_accuracy: 0.9845\n","Epoch 20/50\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0131 - accuracy: 0.9957 - val_loss: 0.0498 - val_accuracy: 0.9856\n","Epoch 21/50\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0111 - accuracy: 0.9968 - val_loss: 0.0423 - val_accuracy: 0.9870\n","Epoch 22/50\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0104 - accuracy: 0.9967 - val_loss: 0.0415 - val_accuracy: 0.9886\n","Epoch 23/50\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0095 - accuracy: 0.9970 - val_loss: 0.0530 - val_accuracy: 0.9851\n","Epoch 24/50\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0100 - accuracy: 0.9968 - val_loss: 0.0504 - val_accuracy: 0.9861\n","Epoch 25/50\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0087 - accuracy: 0.9974 - val_loss: 0.0385 - val_accuracy: 0.9887\n","Epoch 26/50\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0076 - accuracy: 0.9976 - val_loss: 0.0500 - val_accuracy: 0.9878\n","Epoch 27/50\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0062 - accuracy: 0.9982 - val_loss: 0.0431 - val_accuracy: 0.9884\n","Epoch 28/50\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0061 - accuracy: 0.9983 - val_loss: 0.0411 - val_accuracy: 0.9882\n","Epoch 29/50\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0046 - accuracy: 0.9986 - val_loss: 0.0441 - val_accuracy: 0.9880\n","Epoch 30/50\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0038 - accuracy: 0.9990 - val_loss: 0.0445 - val_accuracy: 0.9879\n","Epoch 31/50\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 0.0753 - val_accuracy: 0.9800\n","Epoch 32/50\n","469/469 [==============================] - 5s 10ms/step - loss: 0.0039 - accuracy: 0.9989 - val_loss: 0.0451 - val_accuracy: 0.9883\n","Epoch 33/50\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0035 - accuracy: 0.9989 - val_loss: 0.0462 - val_accuracy: 0.9885\n","Epoch 34/50\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0037 - accuracy: 0.9990 - val_loss: 0.0480 - val_accuracy: 0.9876\n","Epoch 35/50\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0038 - accuracy: 0.9988 - val_loss: 0.0589 - val_accuracy: 0.9868\n","Epoch 36/50\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0052 - accuracy: 0.9982 - val_loss: 0.0486 - val_accuracy: 0.9883\n","Epoch 37/50\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0055 - accuracy: 0.9982 - val_loss: 0.0485 - val_accuracy: 0.9887\n","Epoch 38/50\n","469/469 [==============================] - 4s 7ms/step - loss: 0.0026 - accuracy: 0.9993 - val_loss: 0.0507 - val_accuracy: 0.9884\n","Epoch 39/50\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0030 - accuracy: 0.9991 - val_loss: 0.0574 - val_accuracy: 0.9868\n","Epoch 40/50\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0032 - accuracy: 0.9991 - val_loss: 0.0489 - val_accuracy: 0.9888\n","Epoch 41/50\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0043 - accuracy: 0.9986 - val_loss: 0.0559 - val_accuracy: 0.9863\n","Epoch 42/50\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0483 - val_accuracy: 0.9883\n","Epoch 43/50\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.0515 - val_accuracy: 0.9880\n","Epoch 44/50\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.0527 - val_accuracy: 0.9889\n","Epoch 45/50\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.0485 - val_accuracy: 0.9889\n","Epoch 46/50\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0015 - accuracy: 0.9997 - val_loss: 0.0487 - val_accuracy: 0.9893\n","Epoch 47/50\n","469/469 [==============================] - 4s 8ms/step - loss: 5.9243e-04 - accuracy: 1.0000 - val_loss: 0.0490 - val_accuracy: 0.9888\n","Epoch 48/50\n","469/469 [==============================] - 4s 8ms/step - loss: 5.4238e-04 - accuracy: 0.9999 - val_loss: 0.0502 - val_accuracy: 0.9888\n","Epoch 49/50\n","469/469 [==============================] - 4s 8ms/step - loss: 4.9556e-04 - accuracy: 0.9999 - val_loss: 0.0513 - val_accuracy: 0.9888\n","Epoch 50/50\n","469/469 [==============================] - 4s 8ms/step - loss: 4.6314e-04 - accuracy: 0.9999 - val_loss: 0.0523 - val_accuracy: 0.9889\n","Test loss: 0.05226760357618332, Test accuracy 0.9889000058174133\n"]}]},{"cell_type":"markdown","source":["#### Discussion\n","### a)\n","\n","We choose to use the method Lenet5. This method has a known accuracy of 98-99%. The input layer of Lenet5 requires 32x32 pixel images. To be able to use this we convert the 28x28 images to 32x32 by padding the data. The Lenet5 contains of seven different layers. Three convolutional layers, two subsampling layers and two fully connected layers. The convolutional layers apply filters to the images to learn properties of a set of neighbouring neurons. The subsampling layers are used to downscale the dimensions of the filters, using average pooling, where the average of each patch of the feature map is calculated. Each subsampling layer is taking away half of the size of the filter batch.  "],"metadata":{"id":"NKlY-A39pduo"}},{"cell_type":"markdown","source":["### b)\n","The advantage of using convolutional layers in this case is that each filter has the properties of the neighbouring neurons. This means that the neurons in each filter are only affected by the neighbouring neurons, in contrast to fully connected layers where every neuron is connected to each other. In the sense of image recognition, it is good to use convolutional layers since a filter property can appear all around the image. Let’s say there is a small car in each of the images. The car appears at different places for each image. The convolutional filter senses that it is a car no matter where it is placed in the picture. If fully connected layers where used it only sees properties of each pixel and would not recognize the car everywhere."],"metadata":{"id":"XCY6-PTYpYuE"}}],"metadata":{"colab":{"collapsed_sections":[],"name":"Assignment_7_NN.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.8.12"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}